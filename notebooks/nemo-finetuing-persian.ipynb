{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096c0963-7d3d-47a6-a375-869f7cf681bf",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78a9972-1039-4661-a49a-03c1188995f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T13:58:18.155186Z",
     "iopub.status.busy": "2025-07-19T13:58:18.154547Z",
     "iopub.status.idle": "2025-07-19T14:02:14.048323Z",
     "shell.execute_reply": "2025-07-19T14:02:14.046689Z",
     "shell.execute_reply.started": "2025-07-19T13:58:18.155126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu128\n",
      "Collecting torch==2.7.1+cu128 (from -r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/torch-2.7.1%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchaudio==2.7.1+cu128 (from -r ../requirements.txt (line 3))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/torchaudio-2.7.1%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting transformers==4.51.3 (from -r ../requirements.txt (line 6))\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting datasets==3.6.0 (from -r ../requirements.txt (line 7))\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting librosa==0.11.0 (from -r ../requirements.txt (line 8))\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting jiwer==3.1.0 (from -r ../requirements.txt (line 9))\n",
      "  Using cached jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting soundfile==0.13.1 (from -r ../requirements.txt (line 10))\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /opt/conda/lib/python3.12/site-packages (from -r ../requirements.txt (line 11)) (4.67.1)\n",
      "Collecting ipython==8.37.0 (from -r ../requirements.txt (line 12))\n",
      "  Using cached ipython-8.37.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting accelerate==1.8.1 (from -r ../requirements.txt (line 13))\n",
      "  Using cached accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting num2fawords==1.1 (from -r ../requirements.txt (line 14))\n",
      "  Using cached num2fawords-1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting parsivar==0.2.3.1 (from -r ../requirements.txt (line 15))\n",
      "  Using cached parsivar-0.2.3.1-py3-none-any.whl.metadata (242 bytes)\n",
      "Collecting pandas==2.3.1 (from -r ../requirements.txt (line 16))\n",
      "  Using cached pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting nemo_toolkit==2.3.2 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached nemo_toolkit-2.3.2-py3-none-any.whl.metadata (79 kB)\n",
      "Collecting numpy==1.26.4 (from -r ../requirements.txt (line 19))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting protobuf==4.24.4 (from -r ../requirements.txt (line 20))\n",
      "  Using cached protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Collecting scikit-learn==1.7.0 (from -r ../requirements.txt (line 21))\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting setuptools==80.9.0 (from -r ../requirements.txt (line 22))\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.1+cu128->-r ../requirements.txt (line 2)) (4.12.2)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch==2.7.1+cu128->-r ../requirements.txt (line 2)) (3.1.5)\n",
      "Collecting fsspec (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.61 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_cuda_nvrtc_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.57 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_cuda_runtime_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.57 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_cuda_cupti_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.7.1.26 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_cudnn_cu12-9.7.1.26-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.3.14 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_cublas_cu12-12.8.3.14-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.41 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_cufft_cu12-11.3.3.41-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.55 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_curand_cu12-10.3.9.55-py3-none-manylinux_2_27_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.2.55 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_cusolver_cu12-11.7.2.55-py3-none-manylinux_2_27_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.7.53 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_cusparse_cu12-12.5.7.53-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.55 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_nvtx_cu12-12.8.55-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.61 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_nvjitlink_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.0.11 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/cu128/nvidia_cufile_cu12-1.13.0.11-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers==4.51.3->-r ../requirements.txt (line 6))\n",
      "  Using cached huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers==4.51.3->-r ../requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers==4.51.3->-r ../requirements.txt (line 6)) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.51.3->-r ../requirements.txt (line 6))\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers==4.51.3->-r ../requirements.txt (line 6)) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.51.3->-r ../requirements.txt (line 6))\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers==4.51.3->-r ../requirements.txt (line 6))\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa==0.11.0->-r ../requirements.txt (line 8))\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa==0.11.0->-r ../requirements.txt (line 8))\n",
      "  Using cached numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting scipy>=1.6.0 (from librosa==0.11.0->-r ../requirements.txt (line 8))\n",
      "  Using cached scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.0 (from librosa==0.11.0->-r ../requirements.txt (line 8))\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.12/site-packages (from librosa==0.11.0->-r ../requirements.txt (line 8)) (5.2.1)\n",
      "Collecting pooch>=1.1 (from librosa==0.11.0->-r ../requirements.txt (line 8))\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa==0.11.0->-r ../requirements.txt (line 8))\n",
      "  Using cached soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa==0.11.0->-r ../requirements.txt (line 8))\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa==0.11.0->-r ../requirements.txt (line 8))\n",
      "  Using cached msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /opt/conda/lib/python3.12/site-packages (from jiwer==3.1.0->-r ../requirements.txt (line 9)) (8.2.1)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer==3.1.0->-r ../requirements.txt (line 9))\n",
      "  Using cached rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.12/site-packages (from soundfile==0.13.1->-r ../requirements.txt (line 10)) (1.17.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython==8.37.0->-r ../requirements.txt (line 12)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.12/site-packages (from ipython==8.37.0->-r ../requirements.txt (line 12)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython==8.37.0->-r ../requirements.txt (line 12)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.12/site-packages (from ipython==8.37.0->-r ../requirements.txt (line 12)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from ipython==8.37.0->-r ../requirements.txt (line 12)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython==8.37.0->-r ../requirements.txt (line 12)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.12/site-packages (from ipython==8.37.0->-r ../requirements.txt (line 12)) (5.14.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate==1.8.1->-r ../requirements.txt (line 13)) (7.0.0)\n",
      "Collecting nltk>=3.6.6 (from parsivar==0.2.3.1->-r ../requirements.txt (line 15))\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas==2.3.1->-r ../requirements.txt (line 16)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas==2.3.1->-r ../requirements.txt (line 16)) (2025.1)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.3.1->-r ../requirements.txt (line 16))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting fsspec (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numba>=0.51.0 (from librosa==0.11.0->-r ../requirements.txt (line 8))\n",
      "  Using cached numba-0.61.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting onnx>=1.7.0 (from nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached onnx-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: ruamel.yaml in /opt/conda/lib/python3.12/site-packages (from nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18)) (0.18.10)\n",
      "Collecting tensorboard (from nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting text-unidecode (from nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting wget (from nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting wrapt (from nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.7.0->-r ../requirements.txt (line 21))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting braceexpand (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting editdistance (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached editdistance-0.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting einops (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting g2p_en (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting kaldi-python-io (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kaldiio (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached kaldiio-2.18.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting lhotse>=1.26.0 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached lhotse-1.30.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting marshmallow (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached marshmallow-4.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting optuna (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pyannote.core (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyannote.metrics (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pydub (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyloudnorm (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting resampy (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sox<=1.5.0 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached sox-1.5.0.tar.gz (63 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25done\n",
      "\u001b[?25hCollecting texterrors<1.0.0 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached texterrors-0.5.1.tar.gz (23 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25done\n",
      "\u001b[?25hCollecting cloudpickle (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting fiddle (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached fiddle-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting hydra-core<=1.3.2,>1.3 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lightning<=2.4.0,>2.2.1 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting omegaconf<=2.3 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting peft (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached peft-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting torchmetrics>=0.11.0 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting wandb (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached wandb-0.21.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting webdataset>=0.2.86 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached webdataset-1.0.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting bitsandbytes==0.45.3 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting inflect (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mediapy==1.1.6 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached mediapy-1.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting sacremoses>=0.0.43 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sentencepiece<1.0.0 (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting num2words (from nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting matplotlib (from mediapy==1.1.6->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting Pillow (from mediapy==1.1.6->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa==0.11.0->-r ../requirements.txt (line 8))\n",
      "  Using cached llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi>=1.0->soundfile==0.13.1->-r ../requirements.txt (line 10)) (2.22)\n",
      "INFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fsspec[http]<=2025.3.0,>=2023.1.0 (from datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached aiohttp-3.12.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3->-r ../requirements.txt (line 6))\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core<=1.3.2,>1.3->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython==8.37.0->-r ../requirements.txt (line 12)) (0.8.4)\n",
      "Collecting cytoolz>=0.10.1 (from lhotse>=1.26.0->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached cytoolz-1.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting intervaltree>=3.1.0 (from lhotse>=1.26.0->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tabulate>=0.8.1 (from lhotse>=1.26.0->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting lilcom>=1.1.0 (from lhotse>=1.26.0->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached lilcom-1.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pytorch-lightning (from lightning<=2.4.0,>2.2.1->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is looking at multiple versions of onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting onnx>=1.7.0 (from nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython==8.37.0->-r ../requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from pooch>=1.1->librosa==0.11.0->-r ../requirements.txt (line 8)) (4.3.6)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython==8.37.0->-r ../requirements.txt (line 12)) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.3.1->-r ../requirements.txt (line 16)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.51.3->-r ../requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.51.3->-r ../requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.51.3->-r ../requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers==4.51.3->-r ../requirements.txt (line 6)) (2025.1.31)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting pybind11 (from texterrors<1.0.0->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached pybind11-3.0.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting plac (from texterrors<1.0.0->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached plac-1.4.5-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting loguru (from texterrors<1.0.0->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting termcolor (from texterrors<1.0.0->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting Levenshtein (from texterrors<1.0.0->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting absl-py (from fiddle->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting graphviz (from fiddle->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting libcst (from fiddle->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached libcst-1.8.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
      "Collecting distance>=0.1.3 (from g2p_en->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached Distance-0.1.3.tar.gz (180 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting more_itertools>=8.5.0 (from inflect->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting typeguard>=4.0.1 (from inflect->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch==2.7.1+cu128->-r ../requirements.txt (line 2)) (3.0.2)\n",
      "Collecting docopt>=0.6.2 (from num2words->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25done\n",
      "\u001b[?25hRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from optuna->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18)) (1.14.1)\n",
      "Collecting colorlog (from optuna->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.12/site-packages (from optuna->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18)) (2.0.38)\n",
      "Collecting sortedcontainers>=2.0.4 (from pyannote.core->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting future>=0.16.0 (from pyloudnorm->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.12/site-packages (from ruamel.yaml->nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18)) (0.2.8)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython==8.37.0->-r ../requirements.txt (line 12)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython==8.37.0->-r ../requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython==8.37.0->-r ../requirements.txt (line 12)) (0.2.3)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached grpcio-1.73.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->nemo_toolkit==2.3.2->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18)) (2.10.6)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached sentry_sdk-2.33.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r ../requirements.txt (line 7)) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r ../requirements.txt (line 7))\n",
      "  Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic>=1.5.0->optuna->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18)) (1.3.9)\n",
      "Collecting toolz>=0.8.0 (from cytoolz>=0.10.1->lhotse>=1.26.0->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached fonttools-4.59.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (107 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->mediapy==1.1.6->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting typer>=0.12.1 (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18)) (2.27.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18)) (3.1.1)\n",
      "Collecting typing-extensions>=4.10.0 (from torch==2.7.1+cu128->-r ../requirements.txt (line 2))\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==2.3.2->-r ../requirements.txt (line 18))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/torch-2.7.1%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (1039.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/torchaudio-2.7.1%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
      "Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "Using cached ipython-8.37.0-py3-none-any.whl (831 kB)\n",
      "Using cached accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "Using cached num2fawords-1.1-py3-none-any.whl (9.8 kB)\n",
      "Using cached parsivar-0.2.3.1-py3-none-any.whl (18.0 MB)\n",
      "Using cached pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "Using cached nemo_toolkit-2.3.2-py3-none-any.whl (6.0 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "Using cached scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Using cached mediapy-1.1.6-py3-none-any.whl (24 kB)\n",
      "Using cached numba-0.61.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_cublas_cu12-12.8.3.14-py3-none-manylinux_2_27_x86_64.whl (609.6 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_cuda_cupti_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_cuda_nvrtc_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_cuda_runtime_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_cudnn_cu12-9.7.1.26-py3-none-manylinux_2_27_x86_64.whl (726.9 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_cufft_cu12-11.3.3.41-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_cufile_cu12-1.13.0.11-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_curand_cu12-10.3.9.55-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_cusolver_cu12-11.7.2.55-py3-none-manylinux_2_27_x86_64.whl (260.4 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_cusparse_cu12-12.5.7.53-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (292.1 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_nvjitlink_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu128/nvidia_nvtx_cu12-12.8.55-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading https://download.pytorch.org/whl/triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached lhotse-1.30.3-py3-none-any.whl (851 kB)\n",
      "Using cached lightning-2.4.0-py3-none-any.whl (810 kB)\n",
      "Downloading msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.1/35.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached webdataset-1.0.2-py3-none-any.whl (74 kB)\n",
      "Using cached braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading editdistance-0.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (418 kB)\n",
      "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached fiddle-0.3.0-py3-none-any.whl (419 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "Using cached inflect-7.5.0-py3-none-any.whl (35 kB)\n",
      "Using cached kaldiio-2.18.1-py3-none-any.whl (29 kB)\n",
      "Using cached marshmallow-4.0.0-py3-none-any.whl (48 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached num2words-0.5.14-py3-none-any.whl (163 kB)\n",
      "Using cached optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "Using cached peft-0.16.0-py3-none-any.whl (472 kB)\n",
      "Using cached pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "Using cached pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
      "Using cached resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Using cached wandb-0.21.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading aiohttp-3.12.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading cytoolz-1.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading grpcio-1.73.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading lilcom-1.8.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92 kB)\n",
      "Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Downloading matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
      "Using cached sentry_sdk-2.33.0-py2.py3-none-any.whl (356 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Using cached typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Downloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (159 kB)\n",
      "Downloading libcst-1.8.2-cp312-cp312-manylinux_2_28_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Using cached plac-1.4.5-py2.py3-none-any.whl (22 kB)\n",
      "Using cached pybind11-3.0.0-py3-none-any.whl (292 kB)\n",
      "Using cached pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime, sox, texterrors, kaldi-python-io, wget, distance, docopt, intervaltree\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?2done\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144592 sha256=90342e1f0ecf43d82cffa07d368a0db7058b7e2cfdc688be0e69ca79efe3d850\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
      "  Building wheel for sox (setup.py) ... \u001b[?2done\n",
      "\u001b[?25h  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40099 sha256=06eb7759d28a2dca1d3f9e95391876936dfed23adae9dfa4002c7b23260c0cb3\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8c/c7/e7/baea1f7e79b9eb53addc81cc9b827424f4a7d8c9cc18c03659\n",
      "  Building wheel for texterrors (setup.py) ... \u001bdone\n",
      "\u001b[?25h  Created wheel for texterrors: filename=texterrors-0.5.1-cp312-cp312-linux_x86_64.whl size=115706 sha256=f00594de66873f800eba03a0b9ed467e364547426e9785ca136147b6bab214df\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e0/8f/81/7df3770dce1fcd6dc49118d4b1766f99334dd2ff43848f3893\n",
      "  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=9005 sha256=0870f4ef9534698344a41524c0ed1d04cfed3e8a076d6acd20a48cf4f29ad745\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8b/a9/7b/af1bff74047bf7dfde7040b8fbe968ebb2f68eeed71249a14c\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9685 sha256=4c6abeedf6fa24e749363bc94e06d75f2ff852cf7f3a6e6a1f73d584a665ce46\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
      "  Building wheel for distance (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for distance: filename=distance-0.1.3-py3-none-any.whl size=16292 sha256=3406106e1ce9703c65943e74c87c732cc435edf792bafc338beea8856ec9da05\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/24/a8/58/407063d8e5c1d4dd6594c99d12baa0108570b56a92325587dd\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13749 sha256=ec046e474c941a695037517710926e5610188786e31cf3b66606be1523cc77d9\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26161 sha256=aca5aac09e96b7a74a3a0138fbfffe5cb09936eb9906eed2f1d43ba772257b6d\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/65/c3/c3/238bf93c243597857edd94ddb0577faa74a8e16e9585896e83\n",
      "Successfully built antlr4-python3-runtime sox texterrors kaldi-python-io wget distance docopt intervaltree\n",
      "Installing collected packages: wget, text-unidecode, sortedcontainers, sentencepiece, pydub, plac, nvidia-cusparselt-cu12, num2fawords, mpmath, docopt, distance, braceexpand, antlr4-python3-runtime, xxhash, wrapt, werkzeug, tzdata, typing-extensions, toolz, threadpoolctl, termcolor, tensorboard-data-server, tabulate, sympy, smmap, shellingham, setuptools, sentry-sdk, safetensors, regex, rapidfuzz, pyparsing, pybind11, pyarrow, protobuf, propcache, Pillow, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, num2words, networkx, multidict, msgpack, more_itertools, mdurl, marshmallow, markdown, loguru, llvmlite, libcst, lazy_loader, kiwisolver, joblib, intervaltree, hf-xet, grpcio, graphviz, future, fsspec, frozenlist, fonttools, filelock, einops, editdistance, dill, cycler, colorlog, cloudpickle, audioread, aiohappyeyeballs, absl-py, yarl, webdataset, typeguard, triton, tensorboard, soxr, sox, soundfile, scipy, sacremoses, pooch, pandas, onnx, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, nltk, multiprocess, markdown-it-py, lilcom, lightning-utilities, Levenshtein, kaldiio, kaldi-python-io, jiwer, ipython, hydra-core, huggingface-hub, gitdb, fiddle, cytoolz, contourpy, aiosignal, tokenizers, texterrors, scikit-learn, rich, resampy, pyloudnorm, pyannote.core, parsivar, nvidia-cusolver-cu12, matplotlib, inflect, gitpython, aiohttp, wandb, typer, transformers, torch, optuna, mediapy, librosa, g2p_en, torchmetrics, torchaudio, pyannote.database, nemo_toolkit, lhotse, datasets, bitsandbytes, accelerate, pytorch-lightning, pyannote.metrics, peft, lightning\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.8.2\n",
      "    Uninstalling setuptools-75.8.2:\n",
      "      Successfully uninstalled setuptools-75.8.2\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 9.0.0\n",
      "    Uninstalling ipython-9.0.0:\n",
      "      Successfully uninstalled ipython-9.0.0\n",
      "Successfully installed Levenshtein-0.27.1 Pillow-11.3.0 absl-py-2.3.1 accelerate-1.8.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 antlr4-python3-runtime-4.9.3 audioread-3.0.1 bitsandbytes-0.45.3 braceexpand-0.1.7 cloudpickle-3.1.1 colorlog-6.9.0 contourpy-1.3.2 cycler-0.12.1 cytoolz-1.0.1 datasets-3.6.0 dill-0.3.8 distance-0.1.3 docopt-0.6.2 editdistance-0.8.1 einops-0.8.1 fiddle-0.3.0 filelock-3.18.0 fonttools-4.59.0 frozenlist-1.7.0 fsspec-2024.12.0 future-1.0.0 g2p_en-2.1.0 gitdb-4.0.12 gitpython-3.1.44 graphviz-0.21 grpcio-1.73.1 hf-xet-1.1.5 huggingface-hub-0.33.4 hydra-core-1.3.2 inflect-7.5.0 intervaltree-3.1.0 ipython-8.37.0 jiwer-3.1.0 joblib-1.5.1 kaldi-python-io-1.2.2 kaldiio-2.18.1 kiwisolver-1.4.8 lazy_loader-0.4 lhotse-1.30.3 libcst-1.8.2 librosa-0.11.0 lightning-2.4.0 lightning-utilities-0.14.3 lilcom-1.8.1 llvmlite-0.44.0 loguru-0.7.3 markdown-3.8.2 markdown-it-py-3.0.0 marshmallow-4.0.0 matplotlib-3.10.3 mdurl-0.1.2 mediapy-1.1.6 more_itertools-10.7.0 mpmath-1.3.0 msgpack-1.1.1 multidict-6.6.3 multiprocess-0.70.16 nemo_toolkit-2.3.2 networkx-3.5 nltk-3.9.1 num2fawords-1.1 num2words-0.5.14 numba-0.61.0 numpy-1.26.4 nvidia-cublas-cu12-12.8.3.14 nvidia-cuda-cupti-cu12-12.8.57 nvidia-cuda-nvrtc-cu12-12.8.61 nvidia-cuda-runtime-cu12-12.8.57 nvidia-cudnn-cu12-9.7.1.26 nvidia-cufft-cu12-11.3.3.41 nvidia-cufile-cu12-1.13.0.11 nvidia-curand-cu12-10.3.9.55 nvidia-cusolver-cu12-11.7.2.55 nvidia-cusparse-cu12-12.5.7.53 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.8.61 nvidia-nvtx-cu12-12.8.55 omegaconf-2.3.0 onnx-1.17.0 optuna-4.4.0 pandas-2.3.1 parsivar-0.2.3.1 peft-0.16.0 plac-1.4.5 pooch-1.8.2 propcache-0.3.2 protobuf-4.24.4 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyarrow-21.0.0 pybind11-3.0.0 pydub-0.25.1 pyloudnorm-0.1.1 pyparsing-3.2.3 pytorch-lightning-2.5.2 rapidfuzz-3.13.0 regex-2024.11.6 resampy-0.4.3 rich-14.0.0 sacremoses-0.1.1 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.16.0 sentencepiece-0.2.0 sentry-sdk-2.33.0 setuptools-80.9.0 shellingham-1.5.4 smmap-5.0.2 sortedcontainers-2.4.0 soundfile-0.13.1 sox-1.5.0 soxr-0.5.0.post1 sympy-1.14.0 tabulate-0.9.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 termcolor-3.1.0 text-unidecode-1.3 texterrors-0.5.1 threadpoolctl-3.6.0 tokenizers-0.21.2 toolz-1.0.0 torch-2.7.1+cu128 torchaudio-2.7.1+cu128 torchmetrics-1.7.4 transformers-4.51.3 triton-3.3.1 typeguard-4.4.4 typer-0.16.0 typing-extensions-4.14.1 tzdata-2025.2 wandb-0.21.0 webdataset-1.0.2 werkzeug-3.1.3 wget-3.2 wrapt-1.17.2 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46515cf8-b75f-4e9d-aabe-1e430ac5e86c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T13:18:04.514140Z",
     "iopub.status.busy": "2025-07-19T13:18:04.512981Z",
     "iopub.status.idle": "2025-07-19T13:18:04.523920Z",
     "shell.execute_reply": "2025-07-19T13:18:04.523234Z",
     "shell.execute_reply.started": "2025-07-19T13:18:04.514087Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"../scripts/speech_to_text_hybrid_rnnt_ctc_bpe.py\"):\n",
    "    !wget -P ../scripts https://raw.githubusercontent.com/NVIDIA/NeMo/refs/heads/main/examples/asr/asr_hybrid_transducer_ctc/speech_to_text_hybrid_rnnt_ctc_bpe.py\n",
    "\n",
    "if not os.path.exists(\"../configs/fastconformer_hybrid_transducer_ctc_bpe.yaml\"):\n",
    "    !wget -P ../configs https://raw.githubusercontent.com/NVIDIA/NeMo/refs/heads/main/examples/asr/conf/fastconformer/hybrid_transducer_ctc/fastconformer_hybrid_transducer_ctc_bpe.yaml\n",
    "\n",
    "if not os.path.exists(\"../scripts/process_asr_text_tokenizer.py\"):\n",
    "    !wget -P ../scripts https://raw.githubusercontent.com/NVIDIA/NeMo/refs/heads/main/scripts/tokenizers/process_asr_text_tokenizer.py\n",
    "\n",
    "if not os.path.exists(\"../scripts/convert_hf_dataset_to_nemo.py\"):\n",
    "    !wget -P ../scripts https://raw.githubusercontent.com/NVIDIA/NeMo/refs/heads/main/scripts/speech_recognition/convert_hf_dataset_to_nemo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa99b54-1d36-47bd-b9de-d47cf4c02e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T13:38:15.945843Z",
     "iopub.status.busy": "2025-07-19T13:38:15.944995Z",
     "iopub.status.idle": "2025-07-19T13:38:29.249744Z",
     "shell.execute_reply": "2025-07-19T13:38:29.248965Z",
     "shell.execute_reply.started": "2025-07-19T13:38:15.945813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 13:38:25 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 13:38:26 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: dummy\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    max_duration: 10\n",
      "    min_duration: 0.5\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    use_lhotse: true\n",
      "    lhotse:\n",
      "      shar_path: /data_artifacts/data/shar/train\n",
      "      batch_duration: 1200\n",
      "      quadratic_duration: 15\n",
      "      num_buckets: 10\n",
      "      num_cuts_for_bins_estimate: 10000\n",
      "      buffer_size: 10000\n",
      "      shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2025-07-19 13:38:26 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /data_artifacts/data/nemo/dev_decoded_exprunner.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 512\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-07-19 13:38:26 nemo_logging:405] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: /data_artifacts/data/nemo/test_decoded_exprunner.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 512\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 13:38:26 nemo_logging:393] PADDING: 0\n",
      "[NeMo I 2025-07-19 13:38:28 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-07-19 13:38:28 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 13:38:28 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 13:38:28 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 13:38:28 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 13:38:29 nemo_logging:393] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/jovyan/.cache/huggingface/hub/models--nvidia--stt_fa_fastconformer_hybrid_large/snapshots/249cf5bf70dda7220a60ddeeecff2f6aad8e1784/stt_fa_fastconformer_hybrid_large.nemo.\n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "asr_model = nemo_asr.models.EncDecHybridRNNTCTCBPEModel.from_pretrained(model_name=\"nvidia/stt_fa_fastconformer_hybrid_large\")\n",
    "cfg = asr_model.cfg\n",
    "OmegaConf.save(cfg, \"../configs/fastconformer_hybrid_transducer_ctc_bpe_persian_pretrained.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e96b82-f624-4018-ae7f-d4ed2633c43f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T12:52:31.426021Z",
     "iopub.status.busy": "2025-07-19T12:52:31.425802Z",
     "iopub.status.idle": "2025-07-19T12:52:31.430997Z",
     "shell.execute_reply": "2025-07-19T12:52:31.430381Z",
     "shell.execute_reply.started": "2025-07-19T12:52:31.426003Z"
    }
   },
   "outputs": [],
   "source": [
    "# python [NEMO_GIT_FOLDER]/scripts/tokenizers/process_asr_text_tokenizer.py \\\n",
    "#   --manifest=\"train_manifest.json\" \\\n",
    "#   --data_root=\"<OUTPUT DIRECTORY FOR TOKENIZER>\" \\\n",
    "#   --vocab_size=1024 \\\n",
    "#   --tokenizer=\"spe\" \\\n",
    "#   --spe_type=\"unigram\" \\\n",
    "#   --spe_character_coverage=1.0 \\\n",
    "#   --no_lower_case \\\n",
    "#   --log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e5619-22f8-4662-9603-ba3456907706",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f1020cf-c2d2-4fc0-9c88-6f8bedabd278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T14:59:03.490634Z",
     "iopub.status.busy": "2025-07-19T14:59:03.489916Z",
     "iopub.status.idle": "2025-07-19T14:59:03.499334Z",
     "shell.execute_reply": "2025-07-19T14:59:03.497294Z",
     "shell.execute_reply.started": "2025-07-19T14:59:03.490580Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys_append\n",
    "from tqdm import tqdm\n",
    "from utils.create_dataset import convert_hf_dataset_nemo\n",
    "from nemo.collections.asr.parts.utils.manifest_utils import read_manifest, write_manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c25acad-3f2b-4a7f-a563-a4167589726f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T14:39:04.548068Z",
     "iopub.status.busy": "2025-07-19T14:39:04.547731Z",
     "iopub.status.idle": "2025-07-19T14:44:14.042939Z",
     "shell.execute_reply": "2025-07-19T14:44:14.041914Z",
     "shell.execute_reply.started": "2025-07-19T14:39:04.548042Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train split: 100%|██████████| 30061/30061 [03:01<00:00, 165.83it/s]\n",
      "Processing dev split: 100%|██████████| 10540/10540 [01:03<00:00, 167.07it/s]\n",
      "Processing test split: 100%|██████████| 10540/10540 [01:01<00:00, 170.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_hf_dataset_nemo(dataset_name=\"hsekhalilian/sorted_commonvoice\", output_dir=\"/home/jovyan/.cache/datasets\", split=\"train\")\n",
    "convert_hf_dataset_nemo(dataset_name=\"hsekhalilian/sorted_commonvoice\", output_dir=\"/home/jovyan/.cache/datasets\", split=\"dev\")\n",
    "convert_hf_dataset_nemo(dataset_name=\"hsekhalilian/sorted_commonvoice\", output_dir=\"/home/jovyan/.cache/datasets\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74681ddc-5c1d-49e7-80c6-e91393580267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:05:09.634973Z",
     "iopub.status.busy": "2025-07-19T15:05:09.634247Z",
     "iopub.status.idle": "2025-07-19T15:05:09.643675Z",
     "shell.execute_reply": "2025-07-19T15:05:09.642087Z",
     "shell.execute_reply.started": "2025-07-19T15:05:09.634900Z"
    }
   },
   "outputs": [],
   "source": [
    "manifest_dir = \"/home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/manifests\"\n",
    "\n",
    "train_manifest = f\"{manifest_dir}/train_manifest.json\"\n",
    "dev_manifest = f\"{manifest_dir}/dev_manifest.json\"\n",
    "test_manifest = f\"{manifest_dir}/test_manifest.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e08dbb39-c6ab-43f4-986b-2973aa3320c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:05:24.921209Z",
     "iopub.status.busy": "2025-07-19T15:05:24.920490Z",
     "iopub.status.idle": "2025-07-19T15:05:24.933108Z",
     "shell.execute_reply": "2025-07-19T15:05:24.931279Z",
     "shell.execute_reply.started": "2025-07-19T15:05:24.921149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Processing pipeline\n",
    "def apply_preprocessors(manifest_data, preprocessors):\n",
    "    for processor in preprocessors:\n",
    "        for idx in tqdm(range(len(manifest_data)), desc=f\"Applying {processor.__name__}\"):\n",
    "            manifest_data[idx] = processor(manifest_data[idx])\n",
    "\n",
    "    print(\"Finished processing manifest !\")\n",
    "    return manifest_data\n",
    "\n",
    "def write_processed_manifest(manifest_data, original_path):\n",
    "    original_manifest_name = os.path.basename(original_path)\n",
    "    new_manifest_name = original_manifest_name.replace(\".json\", \"_processed.json\")\n",
    "\n",
    "    manifest_dir = os.path.split(original_path)[0]\n",
    "    filepath = os.path.join(manifest_dir, new_manifest_name)\n",
    "    write_manifest(filepath, manifest_data)\n",
    "    print(f\"Finished writing manifest: {filepath}\")\n",
    "    \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d204681-0dc8-48ea-90c9-ae32e830bbe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:05:26.273425Z",
     "iopub.status.busy": "2025-07-19T15:05:26.272763Z",
     "iopub.status.idle": "2025-07-19T15:05:26.281529Z",
     "shell.execute_reply": "2025-07-19T15:05:26.279673Z",
     "shell.execute_reply.started": "2025-07-19T15:05:26.273367Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_nothing(sample):\n",
    "    return sample\n",
    "    \n",
    "PREPROCESSORS = [\n",
    "    do_nothing,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a0bcb7b-3bf3-448d-817d-df117b0e49cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:05:59.373967Z",
     "iopub.status.busy": "2025-07-19T15:05:59.373265Z",
     "iopub.status.idle": "2025-07-19T15:06:00.308143Z",
     "shell.execute_reply": "2025-07-19T15:06:00.306831Z",
     "shell.execute_reply.started": "2025-07-19T15:05:59.373909Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying do_nothing: 100%|██████████| 30061/30061 [00:00<00:00, 3072171.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing manifest !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying do_nothing: 100%|██████████| 10540/10540 [00:00<00:00, 3121590.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing manifest !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying do_nothing: 100%|██████████| 10540/10540 [00:00<00:00, 3204172.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing manifest !\n",
      "Finished writing manifest: /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/manifests/train_manifest_processed.json\n",
      "Finished writing manifest: /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/manifests/dev_manifest_processed.json\n",
      "Finished writing manifest: /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/manifests/test_manifest_processed.json\n"
     ]
    }
   ],
   "source": [
    "# Load manifests\n",
    "train_manifest_data = read_manifest(train_manifest)\n",
    "dev_manifest_data = read_manifest(dev_manifest)\n",
    "test_manifest_data = read_manifest(test_manifest)\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data_processed = apply_preprocessors(train_manifest_data, PREPROCESSORS)\n",
    "dev_data_processed = apply_preprocessors(dev_manifest_data, PREPROCESSORS)\n",
    "test_data_processed = apply_preprocessors(test_manifest_data, PREPROCESSORS)\n",
    "\n",
    "# Write new manifests\n",
    "train_manifest_cleaned = write_processed_manifest(train_data_processed, train_manifest)\n",
    "dev_manifest_cleaned = write_processed_manifest(dev_data_processed, dev_manifest)\n",
    "test_manifest_cleaned = write_processed_manifest(test_data_processed, test_manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2737a6c1-3499-4d02-a52c-7311f878910d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:06:14.588750Z",
     "iopub.status.busy": "2025-07-19T15:06:14.588007Z",
     "iopub.status.idle": "2025-07-19T15:06:22.722850Z",
     "shell.execute_reply": "2025-07-19T15:06:22.720875Z",
     "shell.execute_reply.started": "2025-07-19T15:06:14.588691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Corpus already exists at path : /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/text_corpus/document.txt\n",
      "WARNING:root:Model file already exists, overriding old model file !\n",
      "[NeMo I 2025-07-19 15:06:21 nemo_logging:393] Processing /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/text_corpus/document.txt and store at /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/tokenizer_spe_bpe_v1024\n",
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=/home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/text_corpus/document.txt --model_prefix=/home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/tokenizer_spe_bpe_v1024/tokenizer --vocab_size=1024 --shuffle_input_sentence=true --hard_vocab_limit=false --model_type=bpe --character_coverage=1.0 --bos_id=-1 --eos_id=-1 --remove_extra_whitespaces=false\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/text_corpus/document.txt\n",
      "  input_format: \n",
      "  model_prefix: /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/tokenizer_spe_bpe_v1024/tokenizer\n",
      "  model_type: BPE\n",
      "  vocab_size: 1024\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 0\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 0\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/text_corpus/document.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 40601 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=1226322\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=96\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 40601 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 40601\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 29729\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=30475 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8018 size=20 all=2019 active=1800 piece=ین\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3846 size=40 all=2763 active=2544 piece=ام\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2695 size=60 all=3822 active=3603 piece=لی\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1812 size=80 all=4784 active=4565 piece=رو\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1254 size=100 all=5818 active=5599 piece=ده\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1238 min_freq=121\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=973 size=120 all=6828 active=1956 piece=اس\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=791 size=140 all=7557 active=2685 piece=▁مت\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=693 size=160 all=8362 active=3490 piece=اند\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=592 size=180 all=9180 active=4308 piece=▁نیست\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=535 size=200 all=9991 active=5119 piece=اط\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=533 min_freq=103\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=506 size=220 all=10559 active=1521 piece=وری\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=453 size=240 all=11186 active=2148 piece=وت\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=407 size=260 all=11774 active=2736 piece=▁حرف\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=377 size=280 all=12232 active=3194 piece=▁توان\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=352 size=300 all=12793 active=3755 piece=▁لط\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=351 min_freq=91\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=333 size=320 all=13261 active=1464 piece=▁مید\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=308 size=340 all=13600 active=1803 piece=شتر\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=293 size=360 all=14133 active=2336 piece=▁بین\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=277 size=380 all=14511 active=2714 piece=▁دل\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=261 size=400 all=14887 active=3090 piece=رت\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=261 min_freq=80\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=250 size=420 all=15238 active=1294 piece=بال\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=234 size=440 all=15558 active=1614 piece=▁رفتار\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=224 size=460 all=15784 active=1840 piece=▁سب\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=213 size=480 all=16245 active=2301 piece=▁انت\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=205 size=500 all=16555 active=2611 piece=دار\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=205 min_freq=72\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=199 size=520 all=17004 active=1388 piece=▁اتاق\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=193 size=540 all=17378 active=1762 piece=▁شم\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=184 size=560 all=17726 active=2110 piece=ایش\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=173 size=580 all=18023 active=2407 piece=کش\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=167 size=600 all=18395 active=2779 piece=خته\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=167 min_freq=65\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=164 size=620 all=18705 active=1282 piece=▁سف\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=158 size=640 all=18953 active=1530 piece=قا\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=152 size=660 all=19144 active=1721 piece=▁پو\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=147 size=680 all=19296 active=1873 piece=شون\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=143 size=700 all=19666 active=2243 piece=▁اخ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=143 min_freq=59\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=139 size=720 all=19853 active=1174 piece=زین\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136 size=740 all=20137 active=1458 piece=▁همهی\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=132 size=760 all=20426 active=1747 piece=▁شنا\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=127 size=780 all=20518 active=1839 piece=▁تی\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=124 size=800 all=20737 active=2058 piece=▁کشید\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=123 min_freq=53\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=119 size=820 all=21030 active=1324 piece=سانی\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=116 size=840 all=21300 active=1594 piece=▁دیوار\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=112 size=860 all=21586 active=1880 piece=▁آی\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=109 size=880 all=21769 active=2063 piece=▁نزدیک\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=106 size=900 all=21925 active=2219 piece=عات\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=106 min_freq=47\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=104 size=920 all=22161 active=1318 piece=▁موف\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/tokenizer_spe_bpe_v1024/tokenizer.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/tokenizer_spe_bpe_v1024/tokenizer.vocab\n",
      "Serialized tokenizer at location : /home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers/tokenizer_spe_bpe_v1024\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 1024\n",
    "TOKENIZER_TYPE = \"bpe\"\n",
    "tokenizer_dir = \"/home/jovyan/.cache/datasets/hsekhalilian___sorted_commonvoice/tokenizers\"\n",
    "\n",
    "!python ../scripts/process_asr_text_tokenizer.py \\\n",
    "  --manifest=$train_manifest_cleaned,$dev_manifest_cleaned \\\n",
    "  --vocab_size=$VOCAB_SIZE \\\n",
    "  --data_root=$tokenizer_dir \\\n",
    "  --tokenizer=\"spe\" \\\n",
    "  --spe_type=$TOKENIZER_TYPE \\\n",
    "  --spe_character_coverage=1.0 \\\n",
    "  --no_lower_case \\\n",
    "  --log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d74ed4-16e0-49c1-b63f-fc11686cc575",
   "metadata": {},
   "source": [
    "# load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea455af7-d83d-4f2c-b29f-4c50a73fae42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:10:18.674904Z",
     "iopub.status.busy": "2025-07-19T15:10:18.674228Z",
     "iopub.status.idle": "2025-07-19T15:10:42.813275Z",
     "shell.execute_reply": "2025-07-19T15:10:42.812237Z",
     "shell.execute_reply.started": "2025-07-19T15:10:18.674831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 15:10:18 nemo_logging:393] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_fastconformer_hybrid_large_pc/versions/1.21.0/files/stt_en_fastconformer_hybrid_large_pc.nemo to /home/jovyan/.cache/torch/NeMo/NeMo_2.3.2/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo\n",
      "[NeMo I 2025-07-19 15:10:38 nemo_logging:393] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2025-07-19 15:10:39 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 15:10:40 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: false\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 1.0\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-07-19 15:10:40 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: fisher_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: europarl_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: librispeech_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mcv11_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: nsc1_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: spgi_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: voxpopuli_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mls_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    max_duration: 20\n",
      "    \n",
      "[NeMo W 2025-07-19 15:10:40 nemo_logging:405] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 15:10:40 nemo_logging:393] PADDING: 0\n",
      "[NeMo I 2025-07-19 15:10:42 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-07-19 15:10:42 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 15:10:42 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 15:10:42 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 15:10:42 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 15:10:42 nemo_logging:393] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/jovyan/.cache/torch/NeMo/NeMo_2.3.2/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "asr_model = nemo_asr.models.EncDecHybridRNNTCTCBPEModel.from_pretrained(model_name=\"stt_en_fastconformer_hybrid_large_pc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5eb999b7-9b3b-4328-8c16-ad54f3d4060a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:11:23.957561Z",
     "iopub.status.busy": "2025-07-19T15:11:23.956825Z",
     "iopub.status.idle": "2025-07-19T15:11:23.966416Z",
     "shell.execute_reply": "2025-07-19T15:11:23.964121Z",
     "shell.execute_reply.started": "2025-07-19T15:11:23.957503Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_decoder = asr_model.decoder.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b051a05a-0ceb-4a68-92da-f447497bea69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:13:57.948116Z",
     "iopub.status.busy": "2025-07-19T15:13:57.947408Z",
     "iopub.status.idle": "2025-07-19T15:13:59.370965Z",
     "shell.execute_reply": "2025-07-19T15:13:59.369977Z",
     "shell.execute_reply.started": "2025-07-19T15:13:57.948055Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 15:13:57 nemo_logging:405] You tried to register an artifact under config key=tokenizer.model_path but an artifact for it has already been registered.\n",
      "[NeMo W 2025-07-19 15:13:57 nemo_logging:405] You tried to register an artifact under config key=tokenizer.vocab_path but an artifact for it has already been registered.\n",
      "[NeMo W 2025-07-19 15:13:57 nemo_logging:405] You tried to register an artifact under config key=tokenizer.spe_tokenizer_vocab but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 15:13:57 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-07-19 15:13:58 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 15:13:58 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 15:13:58 nemo_logging:393] Changed tokenizer of the RNNT decoder to ['<unk>', '▁ب', '▁ا', '▁م', '▁د', '▁ک', 'را', 'ان', 'ار', 'ست', '▁ت', '▁خ', 'ای', 'ند', '▁ن', 'رد', '▁ش', '▁می', '▁و', '▁پ', 'ین', '▁را', '▁س', '▁به', 'ود', '▁ه', '▁ر', '▁او', 'ید', 'اد', '▁در', '▁آ', '▁با', '▁چ', '▁ج', '▁از', '▁است', '▁ز', 'های', '▁کرد', 'ام', 'یم', '▁این', '▁گ', 'ال', '▁ح', '▁خو', 'اه', 'یر', '▁ی', '▁که', 'ور', '▁ف', 'شت', '▁من', 'ون', 'فت', 'هی', '▁رو', '▁ق', 'لی', '▁شد', 'ها', '▁بر', '▁ع', 'اب', '▁بود', '▁تو', '▁هم', '▁کن', 'ری', '▁دار', '▁خود', '▁برا', 'از', 'خت', 'می', '▁یک', 'سی', '▁دو', 'رو', 'ات', '▁ص', '▁آن', 'نگ', '▁بی', '▁ل', '▁میک', 'وی', 'اری', '▁برای', 'لا', 'ران', 'مان', '▁سر', '▁ما', '▁مو', 'ما', 'اشت', '▁پی', 'ده', 'وان', 'ول', 'زی', '▁داد', 'گی', '▁کار', '▁نی', 'تر', 'بی', 'تی', 'انه', '▁دی', 'نی', '▁خواه', '▁تا', '▁کردن', 'انی', 'در', '▁پر', 'اس', 'گر', 'وش', '▁چه', '▁مح', 'نج', '▁ط', '▁شده', 'اق', 'ایی', '▁هست', '▁دست', 'رف', '▁چی', '▁بد', '▁دارد', 'خو', 'اید', '▁میش', '▁رفت', '▁مت', '▁نمی', '▁مر', '▁خی', '▁گر', '▁ای', '▁باش', 'وم', 'قی', '▁سا', '▁غ', 'دی', 'بر', 'اده', 'جا', '▁ند', 'اش', 'هر', '▁داشت', 'کن', 'اند', 'نده', '▁ام', 'گاه', '▁پس', '▁شما', 'دا', 'عی', 'له', '▁کش', 'کی', '▁مع', 'ره', '▁پیش', '▁بز', 'رم', '▁مرد', 'گه', 'عت', '▁روی', '▁نیست', 'شم', 'اره', '▁زی', 'نه', '▁ان', '▁تر', '▁کنم', 'کت', 'بت', 'اف', '▁سی', '▁هر', '▁روز', 'الی', 'وز', 'است', 'مد', '▁گرفت', 'به', 'اط', '▁خیلی', '▁نش', '▁کم', '▁میکند', '▁مس', '▁بخ', '▁راه', 'رار', '▁ات', '▁زد', '▁یه', 'گیر', 'لو', '▁دوست', 'یده', '▁فر', 'شک', '▁چند', 'فا', 'وری', 'لم', '▁زند', '▁سال', '▁رس', 'ارد', '▁باز', '▁باید', '▁حال', 'یش', 'توان', 'ههای', '▁صد', 'نا', '▁ده', 'قت', '▁نو', '▁تم', '▁مد', '▁کند', 'وت', 'مین', '▁یا', 'کر', '▁بیم', 'ادی', 'رای', '▁کرده', '▁تح', 'عد', 'خی', 'شی', '▁هی', '▁میکرد', 'نام', 'ورد', '▁زن', 'چه', '▁آنها', '▁دارم', '▁حرف', '▁مرا', '▁مج', 'وا', 'فر', '▁نه', '▁حس', '▁خوب', '▁شو', '▁پای', '▁میکن', 'که', '▁پول', '▁عم', '▁نم', '▁میشود', '▁همه', '▁آب', '▁خان', 'هم', '▁توان', '▁کنید', 'رگ', 'صی', 'وه', '▁نظ', '▁اون', 'سته', '▁تن', '▁بسی', 'اک', 'دم', '..', 'تاب', 'یدن', '▁سو', '▁اگر', '▁میز', '▁اس', 'ونی', '▁لط', '▁گفت', '▁خواهم', 'قه', '▁گذ', '▁تص', '▁شک', '▁نب', '▁نام', '▁اند', '▁پنج', 'وب', 'عه', 'بار', 'زار', '▁مخ', '▁برد', 'جه', '▁قرار', 'لت', '▁مید', '▁شر', '▁خواهد', '▁شدن', '▁میخو', 'وس', '▁لطفا', '▁زندگی', '▁نق', '▁کسی', '▁ساخت', '▁بل', '▁مق', 'اهی', 'بین', '▁آم', '▁هیچ', '▁پدر', '▁میتوان', 'دید', 'شتر', 'گان', '▁جم', '▁اد', '▁اف', 'با', 'گذ', '▁بده', '▁زمین', '▁صدای', '▁کردند', 'رش', '▁پیر', '▁نا', '▁چرا', 'سه', '▁دا', 'ستان', 'فی', 'کار', '▁بین', '▁تمام', 'بان', 'ونه', '▁تع', '▁تق', 'جود', '▁ری', '▁مش', '▁بزرگ', 'رات', '▁جه', 'رز', 'شین', '▁بسیار', '▁اینجا', '▁شهر', '▁کام', '▁دیگر', '▁ولی', '▁دل', '▁اح', '▁ال', '▁جنگ', '▁کتاب', '▁هستند', 'اخت', '▁جو', '▁کردم', '▁فکر', 'ترین', '▁واق', '▁خوش', '▁دور', '▁تل', '▁کی', '▁مث', '▁های', '▁اص', 'هایی', 'رت', 'ندی', '▁خط', '▁ساز', '▁بودند', '▁شب', '▁چیزی', 'وق', '▁ساعت', '▁صح', '▁هن', '▁خانه', '▁ها', 'وار', 'نامه', '▁بار', '▁خاط', '▁رنگ', '▁فق', '▁میده', 'بال', 'انش', 'لیس', 'مت', '▁بش', '▁کشور', '▁زیر', '▁فرو', '▁خورد', '▁بیشتر', '▁وجود', '▁بعد', '▁کجا', '▁اول', '▁جای', 'ازه', '▁خر', '▁انگ', '▁دری', 'وند', '▁رفتار', 'رام', '▁اج', '▁برخی', '▁حق', '▁نس', '▁دادن', '▁سه', '▁فی', '▁لب', '▁مورد', '▁هستم', '▁جن', '▁مه', '▁شود', '▁خدا', '▁کنیم', 'جی', '▁نز', '▁انج', '▁سب', '▁افت', 'مل', 'ویی', 'ضی', 'شان', '▁پار', '▁آورد', 'لام', 'گرد', 'ستم', '▁ض', 'کم', '▁آز', '▁روش', '▁وی', '▁چیز', 'یشه', 'طور', 'کان', '▁انت', '▁گوش', 'ورت', 'یدم', '▁پرو', '▁باشد', '▁نیاز', 'عا', '▁ماد', '▁نظر', 'کا', '▁،', 'باز', '▁مردم', '▁تب', '▁شع', '▁وق', '▁کو', '▁میر', 'ئی', 'دار', '▁بن', 'گران', 'هن', 'قدر', '▁مم', 'گو', 'لات', 'کرد', '▁خاطر', '▁انجام', 'ارم', 'راک', '▁گل', '▁بگیر', 'خانه', '▁خبر', '▁کنی', 'ابل', '▁بیر', '▁اتاق', '▁شرکت', 'رب', 'لب', '▁جلو', 'سم', '▁گرد', '▁جدید', '▁دیگه', 'اپ', '▁مست', 'زه', '▁قب', '▁بازی', '▁کنند', '▁زود', '▁سخت', '▁فقط', '▁داده', 'شتی', '▁شم', '▁شی', '▁پرد', '▁سنگ', '▁شیر', '▁ندارد', '▁یکی', 'باره', 'مانی', '▁جان', '▁بدون', '▁؟', '▁آمد', '▁بیا', 'رخ', 'نم', 'کس', 'تون', '▁اط', '▁بخش', 'ایش', '▁خواب', '▁درست', '▁ماشین', '▁میکنند', 'حی', '▁اع', '▁توی', 'نو', '▁بچه', '▁ایران', '▁یاد', '▁جوان', 'ایت', '▁شه', 'میم', '▁کل', '▁وقت', '▁تاری', '▁سرباز', 'کش', '▁سپ', '▁ببین', '▁وقتی', '▁پاس', '▁کمی', '▁ث', 'ستی', 'شته', 'فته', 'راب', '▁عق', '▁مط', '▁چون', '▁توانم', 'زد', 'ازی', '▁غیر', '▁حساب', '▁پوش', 'خته', 'سان', 'ندان', '▁چشم', '▁ذ', '▁پا', '▁دخت', '▁فرا', 'خش', 'غی', 'ارت', '▁تج', '▁ته', '▁مدر', '▁بلند', '▁بودن', '▁بیرون', '▁دارید', '▁بیماری', '▁جا', '▁سف', '▁رود', '▁گذاشت', 'پی', '▁خودش', '▁نبود', 'یمی', '▁برگ', '▁بست', '▁جام', '▁دولت', '▁توس', '▁مثل', '▁زیاد', 'یدا', '▁میان', '▁بیمار', 'فه', '▁زدن', '▁نشان', 'قا', '...', 'عیت', '▁خوراک', 'ثر', 'میز', '▁دانش', '▁دریا', '▁صورت', '▁همیشه', '▁مان', '▁کود', 'اهد', 'روع', '▁ظ', '▁حالا', '▁رسید', 'خم', 'یری', '▁خار', '▁پو', 'فاده', '▁دقی', '▁پسر', '▁بودم', '▁کاری', '▁میدهد', 'نین', '▁بع', '▁سخ', '▁چش', '▁گو', '▁گی', '▁هوا', '▁پشت', '▁وارد', '▁همین', '▁تصمیم', 'اسی', '▁زبان', 'شون', '▁جل', '▁نگاه', '▁هنوز', 'مه', 'ایه', 'ینی', '▁وا', 'گیری', '▁کمک', 'الت', '▁تش', '▁طول', '▁نسبت', '▁داشته', 'لاق', 'گری', '▁شعر', '▁بالا', 'یره', '▁اخ', '▁شن', '▁قد', '▁نکن', '▁دارند', '▁استفاده', 'رسی', '▁جز', '▁کوچ', '▁شروع', '▁واقعا', 'ایل', '▁رد', '▁باشه', '▁خوبی', 'اص', 'اشی', '▁درد', '▁میگ', '▁جهان', 'زین', '▁مرت', '▁چهار', '▁دن', '▁شا', '▁برو', '▁مرگ', '▁داری', '▁فیلم', 'ضا', 'طی', 'وع', 'هاش', 'گار', '▁اش', '▁اه', '▁درآ', '▁قط', 'گذار', '▁میخ', '▁همهی', 'تش', '▁خواست', '▁نداشت', '▁حی', '▁مص', '▁تاب', '▁شوهر', 'خص', 'شه', '▁ژ', 'ومی', 'ونم', '▁حل', '▁سفر', '▁داره', '▁دنبال', '▁چندین', 'امی', '▁حر', '▁شنا', '▁رفتن', '▁ممکن', '▁پلیس', '▁اب', '▁سخن', '▁میآ', '▁تنها', '▁صحبت', '▁قابل', 'خر', '▁داریم', '▁زیادی', '▁سربازان', '▁.', '▁تغی', '▁نزدی', '▁ست', '▁مشک', '▁چطور', '▁تی', '▁پرس', 'اتی', '▁اعت', '▁دیر', '▁میشه', '▁سازمان', '▁عن', '▁خون', '▁دنی', '▁نگه', '▁زمان', 'جب', 'بیل', 'نگی', '▁دید', '▁عمل', '▁مخت', 'ندگان', '▁پیدا', '▁کشید', '▁مل', '▁تلف', '▁دارای', '▁پیشنه', '▁تک', 'رانی', '▁خاک', 'ذیر', '▁قر', 'انهی', '▁کاملا', '▁ساختمان', 'سب', '▁تف', '▁نف', '▁لباس', 'حت', 'ورم', 'داری', 'سانی', '▁انداخت', 'سد', '▁حا', '▁لی', 'اندن', 'ندهی', '▁ماه', '▁میکنم', 'زن', '▁کر', '▁اگه', '▁ترس', '▁چقدر', 'چی', 'روی', '▁دشم', '▁موق', '▁بهتر', '▁ماهی', '▁دیوار', 'تم', 'افی', 'برد', '▁غذ', '▁کا', '▁زیب', '▁منظ', '▁خانو', '▁پاسخ', '▁تاریخ', 'ابی', 'ازم', '▁طرف', '▁دربار', 'اح', 'خصی', '▁چشمان', 'لف', 'دود', '▁آی', '▁پن', 'مرد', '▁قدر', '▁هفت', '▁عنوان', 'دام', '▁بح', '▁هو', '▁پز', 'اران', 'خورد', '▁حتی', '▁برادر', '▁پرداخت', '▁ور', '▁سرم', '▁ایست', '▁خودت', '▁دشمن', '▁نزدیک', '▁حرفهای', '▁میکردند', '▁پیشنهاد', 'شن', 'ریف', '▁پل', 'وشید', '▁صدا', '▁اینکه', '▁خانهی', '▁گرفته', 'راز', '▁کف', '▁نفر', '▁کنار', '▁کردیم', '▁برنامه', 'وط', 'گز', 'عات', 'ایید', 'داشت', '▁تول', '▁شور', '▁فرد', '▁اصلا', '▁حقوق', 'مو', 'بور', '▁بال', '▁برف', '▁گرفتن', 'سل', 'امل', '▁اک', '▁مذ', '▁باد', '▁تند', '▁مهم', '▁موف', '▁شاید', '▁تغییر', 'وله', '▁حم', '▁مغ', '▁سری', '▁توانید', '▁', 'ا', 'ی', 'ر', 'د', 'ن', 'م', 'و', 'ه', 'ت', 'ب', 'س', 'ک', 'ش', 'ل', 'ز', 'خ', '.', 'گ', 'ف', 'ق', 'پ', 'ج', 'ع', 'ح', 'چ', 'آ', 'ص', 'ط', '،', '؟', 'غ', 'ض', 'ذ', 'ظ', 'ث', '!', 'ئ', 'ژ', ':', '-', '\"', '«', '»', 'e', 'a', 'n', 'r', 'i', 't', 'o', ',', 's', '؛', '(', ')', 'l', 'u', 'c', 'h', 'S', 'd', 'A', 'B', 'C', 'T', 'G', 'H', 'y', 'I', 'L', 'M', 'm', 'p', 'x', 'F', 'K', 'R', 'b', 'k', 'w', '–', 'D', 'E', 'Q', 'W', 'g', '&', \"'\", '=', 'P', 'U', 'V', 'Z', 'f', 'v'] vocabulary.\n",
      "[NeMo I 2025-07-19 15:13:58 nemo_logging:393] \n",
      "    Replacing old number of classes (1024) with new number of classes - 1024\n",
      "[NeMo I 2025-07-19 15:13:59 nemo_logging:393] Changed tokenizer of the CTC decoder to ['<unk>', '▁ب', '▁ا', '▁م', '▁د', '▁ک', 'را', 'ان', 'ار', 'ست', '▁ت', '▁خ', 'ای', 'ند', '▁ن', 'رد', '▁ش', '▁می', '▁و', '▁پ', 'ین', '▁را', '▁س', '▁به', 'ود', '▁ه', '▁ر', '▁او', 'ید', 'اد', '▁در', '▁آ', '▁با', '▁چ', '▁ج', '▁از', '▁است', '▁ز', 'های', '▁کرد', 'ام', 'یم', '▁این', '▁گ', 'ال', '▁ح', '▁خو', 'اه', 'یر', '▁ی', '▁که', 'ور', '▁ف', 'شت', '▁من', 'ون', 'فت', 'هی', '▁رو', '▁ق', 'لی', '▁شد', 'ها', '▁بر', '▁ع', 'اب', '▁بود', '▁تو', '▁هم', '▁کن', 'ری', '▁دار', '▁خود', '▁برا', 'از', 'خت', 'می', '▁یک', 'سی', '▁دو', 'رو', 'ات', '▁ص', '▁آن', 'نگ', '▁بی', '▁ل', '▁میک', 'وی', 'اری', '▁برای', 'لا', 'ران', 'مان', '▁سر', '▁ما', '▁مو', 'ما', 'اشت', '▁پی', 'ده', 'وان', 'ول', 'زی', '▁داد', 'گی', '▁کار', '▁نی', 'تر', 'بی', 'تی', 'انه', '▁دی', 'نی', '▁خواه', '▁تا', '▁کردن', 'انی', 'در', '▁پر', 'اس', 'گر', 'وش', '▁چه', '▁مح', 'نج', '▁ط', '▁شده', 'اق', 'ایی', '▁هست', '▁دست', 'رف', '▁چی', '▁بد', '▁دارد', 'خو', 'اید', '▁میش', '▁رفت', '▁مت', '▁نمی', '▁مر', '▁خی', '▁گر', '▁ای', '▁باش', 'وم', 'قی', '▁سا', '▁غ', 'دی', 'بر', 'اده', 'جا', '▁ند', 'اش', 'هر', '▁داشت', 'کن', 'اند', 'نده', '▁ام', 'گاه', '▁پس', '▁شما', 'دا', 'عی', 'له', '▁کش', 'کی', '▁مع', 'ره', '▁پیش', '▁بز', 'رم', '▁مرد', 'گه', 'عت', '▁روی', '▁نیست', 'شم', 'اره', '▁زی', 'نه', '▁ان', '▁تر', '▁کنم', 'کت', 'بت', 'اف', '▁سی', '▁هر', '▁روز', 'الی', 'وز', 'است', 'مد', '▁گرفت', 'به', 'اط', '▁خیلی', '▁نش', '▁کم', '▁میکند', '▁مس', '▁بخ', '▁راه', 'رار', '▁ات', '▁زد', '▁یه', 'گیر', 'لو', '▁دوست', 'یده', '▁فر', 'شک', '▁چند', 'فا', 'وری', 'لم', '▁زند', '▁سال', '▁رس', 'ارد', '▁باز', '▁باید', '▁حال', 'یش', 'توان', 'ههای', '▁صد', 'نا', '▁ده', 'قت', '▁نو', '▁تم', '▁مد', '▁کند', 'وت', 'مین', '▁یا', 'کر', '▁بیم', 'ادی', 'رای', '▁کرده', '▁تح', 'عد', 'خی', 'شی', '▁هی', '▁میکرد', 'نام', 'ورد', '▁زن', 'چه', '▁آنها', '▁دارم', '▁حرف', '▁مرا', '▁مج', 'وا', 'فر', '▁نه', '▁حس', '▁خوب', '▁شو', '▁پای', '▁میکن', 'که', '▁پول', '▁عم', '▁نم', '▁میشود', '▁همه', '▁آب', '▁خان', 'هم', '▁توان', '▁کنید', 'رگ', 'صی', 'وه', '▁نظ', '▁اون', 'سته', '▁تن', '▁بسی', 'اک', 'دم', '..', 'تاب', 'یدن', '▁سو', '▁اگر', '▁میز', '▁اس', 'ونی', '▁لط', '▁گفت', '▁خواهم', 'قه', '▁گذ', '▁تص', '▁شک', '▁نب', '▁نام', '▁اند', '▁پنج', 'وب', 'عه', 'بار', 'زار', '▁مخ', '▁برد', 'جه', '▁قرار', 'لت', '▁مید', '▁شر', '▁خواهد', '▁شدن', '▁میخو', 'وس', '▁لطفا', '▁زندگی', '▁نق', '▁کسی', '▁ساخت', '▁بل', '▁مق', 'اهی', 'بین', '▁آم', '▁هیچ', '▁پدر', '▁میتوان', 'دید', 'شتر', 'گان', '▁جم', '▁اد', '▁اف', 'با', 'گذ', '▁بده', '▁زمین', '▁صدای', '▁کردند', 'رش', '▁پیر', '▁نا', '▁چرا', 'سه', '▁دا', 'ستان', 'فی', 'کار', '▁بین', '▁تمام', 'بان', 'ونه', '▁تع', '▁تق', 'جود', '▁ری', '▁مش', '▁بزرگ', 'رات', '▁جه', 'رز', 'شین', '▁بسیار', '▁اینجا', '▁شهر', '▁کام', '▁دیگر', '▁ولی', '▁دل', '▁اح', '▁ال', '▁جنگ', '▁کتاب', '▁هستند', 'اخت', '▁جو', '▁کردم', '▁فکر', 'ترین', '▁واق', '▁خوش', '▁دور', '▁تل', '▁کی', '▁مث', '▁های', '▁اص', 'هایی', 'رت', 'ندی', '▁خط', '▁ساز', '▁بودند', '▁شب', '▁چیزی', 'وق', '▁ساعت', '▁صح', '▁هن', '▁خانه', '▁ها', 'وار', 'نامه', '▁بار', '▁خاط', '▁رنگ', '▁فق', '▁میده', 'بال', 'انش', 'لیس', 'مت', '▁بش', '▁کشور', '▁زیر', '▁فرو', '▁خورد', '▁بیشتر', '▁وجود', '▁بعد', '▁کجا', '▁اول', '▁جای', 'ازه', '▁خر', '▁انگ', '▁دری', 'وند', '▁رفتار', 'رام', '▁اج', '▁برخی', '▁حق', '▁نس', '▁دادن', '▁سه', '▁فی', '▁لب', '▁مورد', '▁هستم', '▁جن', '▁مه', '▁شود', '▁خدا', '▁کنیم', 'جی', '▁نز', '▁انج', '▁سب', '▁افت', 'مل', 'ویی', 'ضی', 'شان', '▁پار', '▁آورد', 'لام', 'گرد', 'ستم', '▁ض', 'کم', '▁آز', '▁روش', '▁وی', '▁چیز', 'یشه', 'طور', 'کان', '▁انت', '▁گوش', 'ورت', 'یدم', '▁پرو', '▁باشد', '▁نیاز', 'عا', '▁ماد', '▁نظر', 'کا', '▁،', 'باز', '▁مردم', '▁تب', '▁شع', '▁وق', '▁کو', '▁میر', 'ئی', 'دار', '▁بن', 'گران', 'هن', 'قدر', '▁مم', 'گو', 'لات', 'کرد', '▁خاطر', '▁انجام', 'ارم', 'راک', '▁گل', '▁بگیر', 'خانه', '▁خبر', '▁کنی', 'ابل', '▁بیر', '▁اتاق', '▁شرکت', 'رب', 'لب', '▁جلو', 'سم', '▁گرد', '▁جدید', '▁دیگه', 'اپ', '▁مست', 'زه', '▁قب', '▁بازی', '▁کنند', '▁زود', '▁سخت', '▁فقط', '▁داده', 'شتی', '▁شم', '▁شی', '▁پرد', '▁سنگ', '▁شیر', '▁ندارد', '▁یکی', 'باره', 'مانی', '▁جان', '▁بدون', '▁؟', '▁آمد', '▁بیا', 'رخ', 'نم', 'کس', 'تون', '▁اط', '▁بخش', 'ایش', '▁خواب', '▁درست', '▁ماشین', '▁میکنند', 'حی', '▁اع', '▁توی', 'نو', '▁بچه', '▁ایران', '▁یاد', '▁جوان', 'ایت', '▁شه', 'میم', '▁کل', '▁وقت', '▁تاری', '▁سرباز', 'کش', '▁سپ', '▁ببین', '▁وقتی', '▁پاس', '▁کمی', '▁ث', 'ستی', 'شته', 'فته', 'راب', '▁عق', '▁مط', '▁چون', '▁توانم', 'زد', 'ازی', '▁غیر', '▁حساب', '▁پوش', 'خته', 'سان', 'ندان', '▁چشم', '▁ذ', '▁پا', '▁دخت', '▁فرا', 'خش', 'غی', 'ارت', '▁تج', '▁ته', '▁مدر', '▁بلند', '▁بودن', '▁بیرون', '▁دارید', '▁بیماری', '▁جا', '▁سف', '▁رود', '▁گذاشت', 'پی', '▁خودش', '▁نبود', 'یمی', '▁برگ', '▁بست', '▁جام', '▁دولت', '▁توس', '▁مثل', '▁زیاد', 'یدا', '▁میان', '▁بیمار', 'فه', '▁زدن', '▁نشان', 'قا', '...', 'عیت', '▁خوراک', 'ثر', 'میز', '▁دانش', '▁دریا', '▁صورت', '▁همیشه', '▁مان', '▁کود', 'اهد', 'روع', '▁ظ', '▁حالا', '▁رسید', 'خم', 'یری', '▁خار', '▁پو', 'فاده', '▁دقی', '▁پسر', '▁بودم', '▁کاری', '▁میدهد', 'نین', '▁بع', '▁سخ', '▁چش', '▁گو', '▁گی', '▁هوا', '▁پشت', '▁وارد', '▁همین', '▁تصمیم', 'اسی', '▁زبان', 'شون', '▁جل', '▁نگاه', '▁هنوز', 'مه', 'ایه', 'ینی', '▁وا', 'گیری', '▁کمک', 'الت', '▁تش', '▁طول', '▁نسبت', '▁داشته', 'لاق', 'گری', '▁شعر', '▁بالا', 'یره', '▁اخ', '▁شن', '▁قد', '▁نکن', '▁دارند', '▁استفاده', 'رسی', '▁جز', '▁کوچ', '▁شروع', '▁واقعا', 'ایل', '▁رد', '▁باشه', '▁خوبی', 'اص', 'اشی', '▁درد', '▁میگ', '▁جهان', 'زین', '▁مرت', '▁چهار', '▁دن', '▁شا', '▁برو', '▁مرگ', '▁داری', '▁فیلم', 'ضا', 'طی', 'وع', 'هاش', 'گار', '▁اش', '▁اه', '▁درآ', '▁قط', 'گذار', '▁میخ', '▁همهی', 'تش', '▁خواست', '▁نداشت', '▁حی', '▁مص', '▁تاب', '▁شوهر', 'خص', 'شه', '▁ژ', 'ومی', 'ونم', '▁حل', '▁سفر', '▁داره', '▁دنبال', '▁چندین', 'امی', '▁حر', '▁شنا', '▁رفتن', '▁ممکن', '▁پلیس', '▁اب', '▁سخن', '▁میآ', '▁تنها', '▁صحبت', '▁قابل', 'خر', '▁داریم', '▁زیادی', '▁سربازان', '▁.', '▁تغی', '▁نزدی', '▁ست', '▁مشک', '▁چطور', '▁تی', '▁پرس', 'اتی', '▁اعت', '▁دیر', '▁میشه', '▁سازمان', '▁عن', '▁خون', '▁دنی', '▁نگه', '▁زمان', 'جب', 'بیل', 'نگی', '▁دید', '▁عمل', '▁مخت', 'ندگان', '▁پیدا', '▁کشید', '▁مل', '▁تلف', '▁دارای', '▁پیشنه', '▁تک', 'رانی', '▁خاک', 'ذیر', '▁قر', 'انهی', '▁کاملا', '▁ساختمان', 'سب', '▁تف', '▁نف', '▁لباس', 'حت', 'ورم', 'داری', 'سانی', '▁انداخت', 'سد', '▁حا', '▁لی', 'اندن', 'ندهی', '▁ماه', '▁میکنم', 'زن', '▁کر', '▁اگه', '▁ترس', '▁چقدر', 'چی', 'روی', '▁دشم', '▁موق', '▁بهتر', '▁ماهی', '▁دیوار', 'تم', 'افی', 'برد', '▁غذ', '▁کا', '▁زیب', '▁منظ', '▁خانو', '▁پاسخ', '▁تاریخ', 'ابی', 'ازم', '▁طرف', '▁دربار', 'اح', 'خصی', '▁چشمان', 'لف', 'دود', '▁آی', '▁پن', 'مرد', '▁قدر', '▁هفت', '▁عنوان', 'دام', '▁بح', '▁هو', '▁پز', 'اران', 'خورد', '▁حتی', '▁برادر', '▁پرداخت', '▁ور', '▁سرم', '▁ایست', '▁خودت', '▁دشمن', '▁نزدیک', '▁حرفهای', '▁میکردند', '▁پیشنهاد', 'شن', 'ریف', '▁پل', 'وشید', '▁صدا', '▁اینکه', '▁خانهی', '▁گرفته', 'راز', '▁کف', '▁نفر', '▁کنار', '▁کردیم', '▁برنامه', 'وط', 'گز', 'عات', 'ایید', 'داشت', '▁تول', '▁شور', '▁فرد', '▁اصلا', '▁حقوق', 'مو', 'بور', '▁بال', '▁برف', '▁گرفتن', 'سل', 'امل', '▁اک', '▁مذ', '▁باد', '▁تند', '▁مهم', '▁موف', '▁شاید', '▁تغییر', 'وله', '▁حم', '▁مغ', '▁سری', '▁توانید', '▁', 'ا', 'ی', 'ر', 'د', 'ن', 'م', 'و', 'ه', 'ت', 'ب', 'س', 'ک', 'ش', 'ل', 'ز', 'خ', '.', 'گ', 'ف', 'ق', 'پ', 'ج', 'ع', 'ح', 'چ', 'آ', 'ص', 'ط', '،', '؟', 'غ', 'ض', 'ذ', 'ظ', 'ث', '!', 'ئ', 'ژ', ':', '-', '\"', '«', '»', 'e', 'a', 'n', 'r', 'i', 't', 'o', ',', 's', '؛', '(', ')', 'l', 'u', 'c', 'h', 'S', 'd', 'A', 'B', 'C', 'T', 'G', 'H', 'y', 'I', 'L', 'M', 'm', 'p', 'x', 'F', 'K', 'R', 'b', 'k', 'w', '–', 'D', 'E', 'Q', 'W', 'g', '&', \"'\", '=', 'P', 'U', 'V', 'Z', 'f', 'v'] vocabulary.\n"
     ]
    }
   ],
   "source": [
    "asr_model.change_vocabulary(new_tokenizer_dir=f\"{tokenizer_dir}/tokenizer_spe_bpe_v1024\", new_tokenizer_type=\"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79701f37-3e3a-4f7f-9a27-4f2a707e1d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:17:35.309506Z",
     "iopub.status.busy": "2025-07-19T15:17:35.308780Z",
     "iopub.status.idle": "2025-07-19T15:17:35.317464Z",
     "shell.execute_reply": "2025-07-19T15:17:35.315662Z",
     "shell.execute_reply.started": "2025-07-19T15:17:35.309449Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Insert preserved model weights if shapes match\n",
    "# if asr_model.decoder.decoder_layers[0].weight.shape == pretrained_decoder['decoder_layers.0.weight'].shape:\n",
    "#     asr_model.decoder.load_state_dict(pretrained_decoder)\n",
    "#     logging.info(\"Decoder shapes matched - restored weights from pre-trained model\")\n",
    "# else:\n",
    "#     logging.info(\"\\nDecoder shapes did not match - could not restore decoder weights from pre-trained model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5387bcf4-f4ad-46f2-809b-af330895d9ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:19:25.066470Z",
     "iopub.status.busy": "2025-07-19T15:19:25.065792Z",
     "iopub.status.idle": "2025-07-19T15:19:25.076034Z",
     "shell.execute_reply": "2025-07-19T15:19:25.074317Z",
     "shell.execute_reply.started": "2025-07-19T15:19:25.066417Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def enable_bn_se(m):\n",
    "    if type(m) == nn.BatchNorm1d:\n",
    "        m.train()\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad_(True)\n",
    "\n",
    "    if 'SqueezeExcite' in type(m).__name__:\n",
    "        m.train()\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6857ef7-efa3-421c-bbd7-35287ff7668d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:20:08.967532Z",
     "iopub.status.busy": "2025-07-19T15:20:08.966778Z",
     "iopub.status.idle": "2025-07-19T15:20:08.977625Z",
     "shell.execute_reply": "2025-07-19T15:20:08.975671Z",
     "shell.execute_reply.started": "2025-07-19T15:20:08.967475Z"
    }
   },
   "outputs": [],
   "source": [
    "from nemo.utils import logging, exp_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36a6803a-b496-43d6-9450-4b67ebcac076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:20:09.812828Z",
     "iopub.status.busy": "2025-07-19T15:20:09.812213Z",
     "iopub.status.idle": "2025-07-19T15:20:09.837399Z",
     "shell.execute_reply": "2025-07-19T15:20:09.835280Z",
     "shell.execute_reply.started": "2025-07-19T15:20:09.812775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 15:20:09 nemo_logging:393] Model encoder has been frozen\n"
     ]
    }
   ],
   "source": [
    "#@title Freeze Encoder { display-mode: \"form\" }\n",
    "freeze_encoder = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "freeze_encoder = bool(freeze_encoder)\n",
    "\n",
    "if freeze_encoder:\n",
    "  asr_model.encoder.freeze()\n",
    "  asr_model.encoder.apply(enable_bn_se)\n",
    "  logging.info(\"Model encoder has been frozen\")\n",
    "else:\n",
    "  asr_model.encoder.unfreeze()\n",
    "  logging.info(\"Model encoder has been un-frozen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "474036bc-d868-49d0-9c52-44c663d7ee7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:21:39.917624Z",
     "iopub.status.busy": "2025-07-19T15:21:39.916897Z",
     "iopub.status.idle": "2025-07-19T15:21:40.295438Z",
     "shell.execute_reply": "2025-07-19T15:21:40.294334Z",
     "shell.execute_reply.started": "2025-07-19T15:21:39.917566Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"../configs/fastconformer_hybrid_transducer_ctc_bpe_persian_pretrained.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "85dbfc36-1eb3-4d6a-943e-47fde010c403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T15:21:41.669752Z",
     "iopub.status.busy": "2025-07-19T15:21:41.669130Z",
     "iopub.status.idle": "2025-07-19T15:21:41.723788Z",
     "shell.execute_reply": "2025-07-19T15:21:41.721516Z",
     "shell.execute_reply.started": "2025-07-19T15:21:41.669696Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dev_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m open_dict(cfg):\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;66;03m# Train dataset  (Concatenate train manifest cleaned and dev manifest cleaned)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m   cfg\u001b[38;5;241m.\u001b[39mtrain_ds\u001b[38;5;241m.\u001b[39mmanifest_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_manifest_cleaned\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdev_manifest_cleaned\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m   cfg\u001b[38;5;241m.\u001b[39mtrain_ds\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mtrain_dev_set\u001b[49m)\n\u001b[1;32m      8\u001b[0m   cfg\u001b[38;5;241m.\u001b[39mtrain_ds\u001b[38;5;241m.\u001b[39mnormalize_transcripts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m   cfg\u001b[38;5;241m.\u001b[39mtrain_ds\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dev_set' is not defined"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "# Setup train, validation, test configs\n",
    "with open_dict(cfg):\n",
    "  # Train dataset  (Concatenate train manifest cleaned and dev manifest cleaned)\n",
    "  cfg.train_ds.manifest_filepath = f\"{train_manifest_cleaned},{dev_manifest_cleaned}\"\n",
    "  cfg.train_ds.labels = list(train_dev_set)\n",
    "  cfg.train_ds.normalize_transcripts = False\n",
    "  cfg.train_ds.batch_size = 4\n",
    "  cfg.train_ds.num_workers = 4\n",
    "  cfg.train_ds.pin_memory = True\n",
    "  cfg.train_ds.trim_silence = True\n",
    "\n",
    "  # Validation dataset  (Use test dataset as validation, since we train using train + dev)\n",
    "  cfg.validation_ds.manifest_filepath = test_manifest_cleaned\n",
    "  cfg.validation_ds.labels = list(train_dev_set)\n",
    "  cfg.validation_ds.normalize_transcripts = False\n",
    "  cfg.validation_ds.batch_size = 8\n",
    "  cfg.validation_ds.num_workers = 4\n",
    "  cfg.validation_ds.pin_memory = True\n",
    "  cfg.validation_ds.trim_silence = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e8b99-5af3-4fea-917f-39f45a4f6673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
