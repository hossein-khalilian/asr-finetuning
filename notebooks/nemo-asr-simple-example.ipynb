{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ba7f9e-4796-481b-8f56-37377dd8c1d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffdfb6d7-5f7d-45f4-b341-7381905e251b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T06:20:32.234208Z",
     "iopub.status.busy": "2025-07-19T06:20:32.233764Z",
     "iopub.status.idle": "2025-07-19T06:20:32.241231Z",
     "shell.execute_reply": "2025-07-19T06:20:32.239920Z",
     "shell.execute_reply.started": "2025-07-19T06:20:32.234161Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd159a9-8676-4744-8cf5-3adcb19c1656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T08:40:25.231522Z",
     "iopub.status.busy": "2025-07-19T08:40:25.231030Z",
     "iopub.status.idle": "2025-07-19T08:40:26.117151Z",
     "shell.execute_reply": "2025-07-19T08:40:26.115900Z",
     "shell.execute_reply.started": "2025-07-19T08:40:25.231482Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p scripts\n",
    "!mkdir -p configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a0101e-2aca-4564-bb39-b36cd846e29f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T08:40:26.119328Z",
     "iopub.status.busy": "2025-07-19T08:40:26.118983Z",
     "iopub.status.idle": "2025-07-19T08:40:26.126235Z",
     "shell.execute_reply": "2025-07-19T08:40:26.125188Z",
     "shell.execute_reply.started": "2025-07-19T08:40:26.119293Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"./scripts/tokenizers/process_asr_text_tokenizer.py\"):\n",
    "  !wget -P scripts/tokenizers/ https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/tokenizers/process_asr_text_tokenizer.py\n",
    "\n",
    "if not os.path.exists(\"./configs/config_bpe.yaml\"):\n",
    "    !wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/asr/conf/citrinet/config_bpe.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c72cd4-8fde-41cb-83a8-0586f8e92125",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f851c3c9-7150-4009-b5fa-22de3010b298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T08:40:26.127568Z",
     "iopub.status.busy": "2025-07-19T08:40:26.127189Z",
     "iopub.status.idle": "2025-07-19T08:40:26.568014Z",
     "shell.execute_reply": "2025-07-19T08:40:26.566830Z",
     "shell.execute_reply.started": "2025-07-19T08:40:26.127535Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/jovyan/.cache/nemo-simple-example/\"\n",
    "!mkdir -p $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a288f3b7-8b57-4bbc-8edb-6a89fb5baeb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T08:40:47.336450Z",
     "iopub.status.busy": "2025-07-19T08:40:47.335276Z",
     "iopub.status.idle": "2025-07-19T08:40:47.350506Z",
     "shell.execute_reply": "2025-07-19T08:40:47.349567Z",
     "shell.execute_reply.started": "2025-07-19T08:40:47.336376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "Tarfile already exists.\n",
      "Finished conversion.\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "import wget\n",
    "\n",
    "def custom_progress_bar(current, total, width=50):\n",
    "    progress = int(width * current / total)\n",
    "    sys.stdout.write('\\r[{}{}] {:.1f}%'.format(\n",
    "        '#' * progress, '.' * (width - progress), 100 * current / total))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "print(\"******\")\n",
    "if not os.path.exists(data_dir + '/an4_sphere.tar.gz'):\n",
    "    print(\"Download the dataset. This will take a few moments...\")\n",
    "    an4_url = 'https://dldata-public.s3.us-east-2.amazonaws.com/an4_sphere.tar.gz'\n",
    "    an4_path = wget.download(an4_url, data_dir, bar=custom_progress_bar)\n",
    "    print(f\"Dataset downloaded at: {an4_path}\")\n",
    "else:\n",
    "    print(\"Tarfile already exists.\")\n",
    "    an4_path = data_dir + '/an4_sphere.tar.gz'\n",
    "\n",
    "if not os.path.exists(data_dir + '/an4/'):\n",
    "    # Untar and convert .sph to .wav (using sox)\n",
    "    tar = tarfile.open(an4_path)\n",
    "    tar.extractall(path=data_dir)\n",
    "\n",
    "    print(\"Converting .sph to .wav...\")\n",
    "    sph_list = glob.glob(data_dir + '/an4/**/*.sph', recursive=True)\n",
    "    for sph_path in sph_list:\n",
    "        wav_path = sph_path[:-4] + '.wav'\n",
    "        cmd = [\"sox\", sph_path, wav_path]\n",
    "        subprocess.run(cmd)\n",
    "print(\"Finished conversion.\\n******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf9d0d3-eebb-46cc-8b6c-8937db972d7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T08:40:48.869374Z",
     "iopub.status.busy": "2025-07-19T08:40:48.868116Z",
     "iopub.status.idle": "2025-07-19T08:40:48.881504Z",
     "shell.execute_reply": "2025-07-19T08:40:48.880812Z",
     "shell.execute_reply.started": "2025-07-19T08:40:48.869338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "Building Manifests...\n",
      "***Done***\n"
     ]
    }
   ],
   "source": [
    "# --- Building Manifest Files --- #\n",
    "import json\n",
    "import librosa\n",
    "\n",
    "# Function to build a manifest\n",
    "def build_manifest(transcripts_path, manifest_path, wav_path):\n",
    "    with open(transcripts_path, 'r') as fin:\n",
    "        with open(manifest_path, 'w') as fout:\n",
    "            for line in fin:\n",
    "                # Lines look like this:\n",
    "                # <s> transcript </s> (fileID)\n",
    "                transcript = line[: line.find('(')-1].lower()\n",
    "                transcript = transcript.replace('<s>', '').replace('</s>', '')\n",
    "                transcript = transcript.strip()\n",
    "\n",
    "                file_id = line[line.find('(')+1 : -2]  # e.g. \"cen4-fash-b\"\n",
    "                audio_path = os.path.join(\n",
    "                    data_dir, wav_path,\n",
    "                    file_id[file_id.find('-')+1 : file_id.rfind('-')],\n",
    "                    file_id + '.wav')\n",
    "\n",
    "                duration = librosa.core.get_duration(filename=audio_path)\n",
    "\n",
    "                # Write the metadata to the manifest\n",
    "                metadata = {\n",
    "                    \"audio_filepath\": audio_path,\n",
    "                    \"duration\": duration,\n",
    "                    \"text\": transcript\n",
    "                }\n",
    "                json.dump(metadata, fout)\n",
    "                fout.write('\\n')\n",
    "                \n",
    "print(\"******\")\n",
    "print(\"Building Manifests...\")\n",
    "train_transcripts = data_dir + '/an4/etc/an4_train.transcription'\n",
    "train_manifest = data_dir + '/an4/train_manifest.json'\n",
    "if not os.path.isfile(train_manifest):\n",
    "    build_manifest(train_transcripts, train_manifest, 'an4/wav/an4_clstk')\n",
    "    print(\"Training manifest created.\")\n",
    "\n",
    "test_transcripts = data_dir + '/an4/etc/an4_test.transcription'\n",
    "test_manifest = data_dir + '/an4/test_manifest.json'\n",
    "if not os.path.isfile(test_manifest):\n",
    "    build_manifest(test_transcripts, test_manifest, 'an4/wav/an4test_clstk')\n",
    "    print(\"Test manifest created.\")\n",
    "print(\"***Done***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d757a2e-3606-40b7-876e-a74f221cf2cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T08:43:05.349926Z",
     "iopub.status.busy": "2025-07-19T08:43:05.349221Z",
     "iopub.status.idle": "2025-07-19T08:43:05.792407Z",
     "shell.execute_reply": "2025-07-19T08:43:05.790876Z",
     "shell.execute_reply.started": "2025-07-19T08:43:05.349890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"audio_filepath\": \"/home/jovyan/.cache/nemo-simple-example/an4/wav/an4_clstk/fash/an251-fash-b.wav\", \"duration\": 1.0, \"text\": \"yes\"}\n",
      "{\"audio_filepath\": \"/home/jovyan/.cache/nemo-simple-example/an4/wav/an4_clstk/fash/an253-fash-b.wav\", \"duration\": 0.7, \"text\": \"go\"}\n",
      "{\"audio_filepath\": \"/home/jovyan/.cache/nemo-simple-example/an4/wav/an4_clstk/fash/an254-fash-b.wav\", \"duration\": 0.9, \"text\": \"yes\"}\n",
      "{\"audio_filepath\": \"/home/jovyan/.cache/nemo-simple-example/an4/wav/an4_clstk/fash/an255-fash-b.wav\", \"duration\": 2.6, \"text\": \"u m n y h six\"}\n",
      "{\"audio_filepath\": \"/home/jovyan/.cache/nemo-simple-example/an4/wav/an4_clstk/fash/cen1-fash-b.wav\", \"duration\": 3.5, \"text\": \"h i n i c h\"}\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 {data_dir}/an4/train_manifest.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90c308-898c-46f7-b5d0-011e7d2b096e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# build tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a17da32-812c-48f0-930d-15978b9e938c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T08:45:10.285967Z",
     "iopub.status.busy": "2025-07-19T08:45:10.285503Z",
     "iopub.status.idle": "2025-07-19T08:45:16.855009Z",
     "shell.execute_reply": "2025-07-19T08:45:16.853907Z",
     "shell.execute_reply.started": "2025-07-19T08:45:10.285921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Corpus already exists at path : /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/text_corpus/document.txt\n",
      "WARNING:root:Model file already exists, overriding old model file !\n",
      "[NeMo I 2025-07-19 08:45:15 nemo_logging:393] Processing /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/text_corpus/document.txt and store at /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/tokenizer_spe_unigram_v32\n",
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=/home/jovyan/.cache/nemo-simple-example//tokenizers/an4/text_corpus/document.txt --model_prefix=/home/jovyan/.cache/nemo-simple-example//tokenizers/an4/tokenizer_spe_unigram_v32/tokenizer --vocab_size=32 --shuffle_input_sentence=true --hard_vocab_limit=false --model_type=unigram --character_coverage=1.0 --bos_id=-1 --eos_id=-1 --remove_extra_whitespaces=false\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/text_corpus/document.txt\n",
      "  input_format: \n",
      "  model_prefix: /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/tokenizer_spe_unigram_v32/tokenizer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 32\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 0\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 0\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/text_corpus/document.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 948 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=18802\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=27\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 948 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=11503\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 247 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 948\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 99\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 99 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=158 obj=6.00125 num_tokens=203 num_tokens/piece=1.28481\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=126 obj=4.95207 num_tokens=204 num_tokens/piece=1.61905\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=94 obj=5.22058 num_tokens=226 num_tokens/piece=2.40426\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=94 obj=5.18753 num_tokens=226 num_tokens/piece=2.40426\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=70 obj=5.738 num_tokens=285 num_tokens/piece=4.07143\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=70 obj=5.65901 num_tokens=285 num_tokens/piece=4.07143\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=52 obj=6.87536 num_tokens=339 num_tokens/piece=6.51923\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=52 obj=6.50325 num_tokens=339 num_tokens/piece=6.51923\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=39 obj=7.48308 num_tokens=391 num_tokens/piece=10.0256\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=39 obj=6.7483 num_tokens=391 num_tokens/piece=10.0256\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=35 obj=7.23831 num_tokens=417 num_tokens/piece=11.9143\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=35 obj=7.14988 num_tokens=417 num_tokens/piece=11.9143\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/tokenizer_spe_unigram_v32/tokenizer.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/tokenizer_spe_unigram_v32/tokenizer.vocab\n",
      "Serialized tokenizer at location : /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/tokenizer_spe_unigram_v32\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "!python ./scripts/tokenizers/process_asr_text_tokenizer.py \\\n",
    "  --manifest=\"{data_dir}/an4/train_manifest.json\" \\\n",
    "  --data_root=\"{data_dir}/tokenizers/an4/\" \\\n",
    "  --vocab_size=32 \\\n",
    "  --tokenizer=\"spe\" \\\n",
    "  --no_lower_case \\\n",
    "  --spe_type=\"unigram\" \\\n",
    "  --log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5246c1d7-3018-4cec-9bc8-08bbca3f7ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T08:45:43.882390Z",
     "iopub.status.busy": "2025-07-19T08:45:43.881963Z",
     "iopub.status.idle": "2025-07-19T08:45:44.327257Z",
     "shell.execute_reply": "2025-07-19T08:45:44.326028Z",
     "shell.execute_reply.started": "2025-07-19T08:45:43.882346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁\n",
      "##e\n",
      "##t\n",
      "##r\n",
      "##o\n",
      "##a\n",
      "##h\n",
      "one\n",
      "two\n",
      "##u\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 {data_dir}/tokenizers/an4/tokenizer_spe_unigram_v32/vocab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4750e92-b6c9-4328-95c0-4e3a189376ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff54d70-5cd2-43b8-8827-887841a56cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:06:27.217404Z",
     "iopub.status.busy": "2025-07-19T09:06:27.216918Z",
     "iopub.status.idle": "2025-07-19T09:06:27.224221Z",
     "shell.execute_reply": "2025-07-19T09:06:27.222955Z",
     "shell.execute_reply.started": "2025-07-19T09:06:27.217357Z"
    }
   },
   "outputs": [],
   "source": [
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from omegaconf import OmegaConf, open_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c55108e9-d61e-42ce-ba00-2e3f7a1fb1f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:06:27.486519Z",
     "iopub.status.busy": "2025-07-19T09:06:27.486083Z",
     "iopub.status.idle": "2025-07-19T09:06:27.524453Z",
     "shell.execute_reply": "2025-07-19T09:06:27.523516Z",
     "shell.execute_reply.started": "2025-07-19T09:06:27.486485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: ContextNet5x1\n",
      "sample_rate: 16000\n",
      "repeat: 1\n",
      "dropout: 0.0\n",
      "separable: true\n",
      "model:\n",
      "  train_ds:\n",
      "    manifest_filepath: ???\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shard_strategy: scatter\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "  validation_ds:\n",
      "    manifest_filepath: ???\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "  tokenizer:\n",
      "    dir: ???\n",
      "    type: ???\n",
      "  preprocessor:\n",
      "    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor\n",
      "    normalize: per_feature\n",
      "    window_size: 0.02\n",
      "    sample_rate: 16000\n",
      "    window_stride: 0.01\n",
      "    window: hann\n",
      "    features: 64\n",
      "    n_fft: 512\n",
      "    frame_splicing: 1\n",
      "    dither: 1.0e-05\n",
      "  spec_augment:\n",
      "    _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
      "    rect_freq: 50\n",
      "    rect_masks: 5\n",
      "    rect_time: 120\n",
      "  encoder:\n",
      "    _target_: nemo.collections.asr.modules.ConvASREncoder\n",
      "    feat_in: 64\n",
      "    activation: relu\n",
      "    conv_mask: true\n",
      "    jasper:\n",
      "    - filters: 128\n",
      "      repeat: 1\n",
      "      kernel:\n",
      "      - 11\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.0\n",
      "      residual: true\n",
      "      separable: true\n",
      "      se: true\n",
      "      se_context_size: -1\n",
      "    - filters: 256\n",
      "      repeat: 1\n",
      "      kernel:\n",
      "      - 13\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.0\n",
      "      residual: true\n",
      "      separable: true\n",
      "      se: true\n",
      "      se_context_size: -1\n",
      "    - filters: 256\n",
      "      repeat: 1\n",
      "      kernel:\n",
      "      - 15\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.0\n",
      "      residual: true\n",
      "      separable: true\n",
      "      se: true\n",
      "      se_context_size: -1\n",
      "    - filters: 256\n",
      "      repeat: 1\n",
      "      kernel:\n",
      "      - 17\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.0\n",
      "      residual: true\n",
      "      separable: true\n",
      "      se: true\n",
      "      se_context_size: -1\n",
      "    - filters: 256\n",
      "      repeat: 1\n",
      "      kernel:\n",
      "      - 19\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.0\n",
      "      residual: true\n",
      "      separable: true\n",
      "      se: true\n",
      "      se_context_size: -1\n",
      "    - filters: 256\n",
      "      repeat: 1\n",
      "      kernel:\n",
      "      - 21\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.0\n",
      "      residual: false\n",
      "      separable: true\n",
      "      se: true\n",
      "      se_context_size: -1\n",
      "    - filters: 1024\n",
      "      repeat: 1\n",
      "      kernel:\n",
      "      - 1\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.0\n",
      "      residual: false\n",
      "      separable: true\n",
      "      se: true\n",
      "      se_context_size: -1\n",
      "  decoder:\n",
      "    _target_: nemo.collections.asr.modules.ConvASRDecoder\n",
      "    feat_in: 1024\n",
      "    num_classes: -1\n",
      "    vocabulary: []\n",
      "  optim:\n",
      "    name: adam\n",
      "    lr: 0.1\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    weight_decay: 0.0001\n",
      "    sched:\n",
      "      name: CosineAnnealing\n",
      "      warmup_steps: null\n",
      "      warmup_ratio: 0.05\n",
      "      min_lr: 1.0e-06\n",
      "      last_epoch: -1\n",
      "trainer:\n",
      "  devices: 1\n",
      "  max_epochs: 5\n",
      "  max_steps: -1\n",
      "  num_nodes: 1\n",
      "  accelerator: gpu\n",
      "  strategy: ddp\n",
      "  accumulate_grad_batches: 1\n",
      "  enable_checkpointing: false\n",
      "  logger: false\n",
      "  log_every_n_steps: 1\n",
      "  val_check_interval: 1.0\n",
      "  benchmark: false\n",
      "exp_manager:\n",
      "  exp_dir: null\n",
      "  name: ContextNet5x1\n",
      "  create_tensorboard_logger: true\n",
      "  create_checkpoint_callback: true\n",
      "  create_wandb_logger: false\n",
      "  wandb_logger_kwargs:\n",
      "    name: null\n",
      "    project: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = OmegaConf.load(\"./configs/config_bpe.yaml\")\n",
    "print(OmegaConf.to_yaml(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "098d6a97-9e8d-4fbb-9cc7-885cc6524c98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:23:22.759195Z",
     "iopub.status.busy": "2025-07-19T09:23:22.758779Z",
     "iopub.status.idle": "2025-07-19T09:23:22.765884Z",
     "shell.execute_reply": "2025-07-19T09:23:22.764897Z",
     "shell.execute_reply.started": "2025-07-19T09:23:22.759162Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/jovyan/.cache/nemo-simple-example/\"\n",
    "train_manifest = data_dir + '/an4/train_manifest.json'\n",
    "test_manifest = data_dir + '/an4/test_manifest.json'\n",
    "\n",
    "params.model.train_ds.manifest_filepath = train_manifest\n",
    "params.model.validation_ds.manifest_filepath = test_manifest\n",
    "\n",
    "params.model.spec_augment.rect_masks = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "947dfdc8-8d19-4609-98f9-f8637f554d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:23:23.807212Z",
     "iopub.status.busy": "2025-07-19T09:23:23.806797Z",
     "iopub.status.idle": "2025-07-19T09:23:23.812856Z",
     "shell.execute_reply": "2025-07-19T09:23:23.811776Z",
     "shell.execute_reply.started": "2025-07-19T09:23:23.807178Z"
    }
   },
   "outputs": [],
   "source": [
    "params.model.tokenizer.dir = data_dir + \"/tokenizers/an4/tokenizer_spe_unigram_v32/\"\n",
    "params.model.tokenizer.type = \"bpe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e9e782-08aa-4424-a992-009766927eed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:07:14.770979Z",
     "iopub.status.busy": "2025-07-19T09:07:14.770543Z",
     "iopub.status.idle": "2025-07-19T09:07:14.803030Z",
     "shell.execute_reply": "2025-07-19T09:07:14.802239Z",
     "shell.execute_reply.started": "2025-07-19T09:07:14.770943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "trainer = pl.Trainer(devices=1, accelerator='gpu', max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "757c9f46-2fa2-4bc9-847d-4ff5505a8ad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:07:17.911682Z",
     "iopub.status.busy": "2025-07-19T09:07:17.911209Z",
     "iopub.status.idle": "2025-07-19T09:07:17.916681Z",
     "shell.execute_reply": "2025-07-19T09:07:17.915719Z",
     "shell.execute_reply.started": "2025-07-19T09:07:17.911645Z"
    }
   },
   "outputs": [],
   "source": [
    "params.model.train_ds.batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe8aa960-e8bd-4367-a2e3-d5949bb861ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:07:18.161866Z",
     "iopub.status.busy": "2025-07-19T09:07:18.161531Z",
     "iopub.status.idle": "2025-07-19T09:07:18.358366Z",
     "shell.execute_reply": "2025-07-19T09:07:18.357527Z",
     "shell.execute_reply.started": "2025-07-19T09:07:18.161838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 09:07:18 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 32 tokens\n",
      "[NeMo I 2025-07-19 09:07:18 nemo_logging:393] \n",
      "    Replacing placeholder number of classes (-1) with actual number of classes - 32\n",
      "[NeMo I 2025-07-19 09:07:18 nemo_logging:393] Dataset loaded with 948 files totalling 0.71 hours\n",
      "[NeMo I 2025-07-19 09:07:18 nemo_logging:393] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2025-07-19 09:07:18 nemo_logging:393] Dataset loaded with 130 files totalling 0.10 hours\n",
      "[NeMo I 2025-07-19 09:07:18 nemo_logging:393] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2025-07-19 09:07:18 nemo_logging:393] PADDING: 16\n"
     ]
    }
   ],
   "source": [
    "first_asr_model = nemo_asr.models.EncDecCTCModelBPE(cfg=params.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f9374c7-8fb3-44ec-a88b-5fcc725254ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:07:29.220931Z",
     "iopub.status.busy": "2025-07-19T09:07:29.220523Z",
     "iopub.status.idle": "2025-07-19T09:08:33.320396Z",
     "shell.execute_reply": "2025-07-19T09:08:33.319465Z",
     "shell.execute_reply.started": "2025-07-19T09:07:29.220898Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 09:07:29 nemo_logging:393] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.999]\n",
      "        capturable: False\n",
      "        decoupled_weight_decay: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.1\n",
      "        maximize: False\n",
      "        weight_decay: 0.0001\n",
      "    )\n",
      "[NeMo I 2025-07-19 09:07:29 nemo_logging:393] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f68b218e1e0>\" \n",
      "    will be used during training (effective maximum steps = 1190) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: 0.05\n",
      "    min_lr: 1.0e-06\n",
      "    last_epoch: -1\n",
      "    max_steps: 1190\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params | Mode \n",
      "--------------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0      | train\n",
      "1 | encoder           | ConvASREncoder                    | 1.2 M  | train\n",
      "2 | decoder           | ConvASRDecoder                    | 33.8 K | train\n",
      "3 | loss              | CTCLoss                           | 0      | train\n",
      "4 | spec_augmentation | SpectrogramAugmentation           | 0      | train\n",
      "5 | wer               | WER                               | 0      | train\n",
      "--------------------------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.852     Total estimated model params size (MB)\n",
      "134       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bca8b6a45ff411abe7a6db9f803dc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0189168d4c474044a1ee0ecbf38b94d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8e8250303940faa2244b8314c4442b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553a5d244df1489793538b65f4b19125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828f4b7f979a4e97a627e1f2ff4e2cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3d9437e3fa4ecc98efe47029105724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be2903aa3d04c0bb87c3a7ce7f68913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faa424eeba642a793c929667082558c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78cfb336c2946be9cc75c0680dbf1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d45a2bc52d4ecb8a5e00118750c1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c86b61f7474eb686708f12fe5ee77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0325f2cf7e485a8626a2343f17c59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(first_asr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cb82579-d5d2-42b5-9180-2f089473ba55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:08:52.788315Z",
     "iopub.status.busy": "2025-07-19T09:08:52.787858Z",
     "iopub.status.idle": "2025-07-19T09:08:52.883509Z",
     "shell.execute_reply": "2025-07-19T09:08:52.882525Z",
     "shell.execute_reply.started": "2025-07-19T09:08:52.788282Z"
    }
   },
   "outputs": [],
   "source": [
    "first_asr_model.save_to(f\"{data_dir}/first_model.nemo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc26ddee-5d04-4225-aa61-0a3078ece746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:09:30.171745Z",
     "iopub.status.busy": "2025-07-19T09:09:30.170623Z",
     "iopub.status.idle": "2025-07-19T09:09:30.176554Z",
     "shell.execute_reply": "2025-07-19T09:09:30.175389Z",
     "shell.execute_reply.started": "2025-07-19T09:09:30.171716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'adam', 'lr': 0.1, 'betas': [0.9, 0.999], 'weight_decay': 0.0001, 'sched': {'name': 'CosineAnnealing', 'warmup_steps': None, 'warmup_ratio': 0.05, 'min_lr': 1e-06, 'last_epoch': -1}}\n"
     ]
    }
   ],
   "source": [
    "print(params.model.optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f523a-3e60-4e49-b3b2-8c07648e2df0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac0e2e5d-9b5d-4187-9642-67685f29d343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:18:05.234662Z",
     "iopub.status.busy": "2025-07-19T09:18:05.234136Z",
     "iopub.status.idle": "2025-07-19T09:18:05.239469Z",
     "shell.execute_reply": "2025-07-19T09:18:05.238502Z",
     "shell.execute_reply.started": "2025-07-19T09:18:05.234627Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/jovyan/.cache/nemo-simple-example/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a645062-dd0b-4a28-8e8a-ff6497c10140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:10:59.929909Z",
     "iopub.status.busy": "2025-07-19T09:10:59.929487Z",
     "iopub.status.idle": "2025-07-19T09:11:00.209554Z",
     "shell.execute_reply": "2025-07-19T09:11:00.208820Z",
     "shell.execute_reply.started": "2025-07-19T09:10:59.929875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 09:11:00 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 32 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 09:11:00 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /home/jovyan/.cache/nemo-simple-example//an4/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shard_strategy: scatter\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-07-19 09:11:00 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /home/jovyan/.cache/nemo-simple-example//an4/test_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 09:11:00 nemo_logging:393] PADDING: 16\n",
      "[NeMo I 2025-07-19 09:11:00 nemo_logging:393] Model EncDecCTCModelBPE was successfully restored from /home/jovyan/.cache/nemo-simple-example/first_model.nemo.\n"
     ]
    }
   ],
   "source": [
    "first_asr_model = nemo_asr.models.EncDecCTCModelBPE.restore_from(f\"{data_dir}/first_model.nemo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5d7680a-d57c-4187-bfc2-688aff391f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:14:24.580801Z",
     "iopub.status.busy": "2025-07-19T09:14:24.580035Z",
     "iopub.status.idle": "2025-07-19T09:14:24.635298Z",
     "shell.execute_reply": "2025-07-19T09:14:24.634806Z",
     "shell.execute_reply.started": "2025-07-19T09:14:24.580764Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 30.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hypothesis(score=tensor(-1.2118), y_sequence=tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32,  1,  1, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32,  1, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,  1,  1, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32,  1, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32,  1, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32]), text='    ', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None), Hypothesis(score=tensor(-1.2226), y_sequence=tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32,  1, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,  1,  1, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32]), text=' ', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None), Hypothesis(score=tensor(-0.3896), y_sequence=tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32,  1, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32]), text='', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None), Hypothesis(score=tensor(0.), y_sequence=tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32]), text='', dec_out=None, dec_state=None, timestamp=[], alignments=None, frame_confidence=None, token_confidence=None, word_confidence=None, length=0, y=None, lm_state=None, lm_scores=None, ngram_lm_state=None, tokens=None, last_token=None, token_duration=None, last_frame=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(first_asr_model.transcribe(audio=[data_dir + '/an4/wav/an4_clstk/mgah/cen2-mgah-b.wav',\n",
    "                                                    data_dir + '/an4/wav/an4_clstk/fmjd/cen7-fmjd-b.wav',\n",
    "                                                    data_dir + '/an4/wav/an4_clstk/fmjd/cen8-fmjd-b.wav',\n",
    "                                                    data_dir + '/an4/wav/an4_clstk/fkai/cen8-fkai-b.wav'],\n",
    "                                 batch_size=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bdf4b66-cdfe-46b2-9d96-d02776942b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:16:15.517594Z",
     "iopub.status.busy": "2025-07-19T09:16:15.517156Z",
     "iopub.status.idle": "2025-07-19T09:16:16.458100Z",
     "shell.execute_reply": "2025-07-19T09:16:16.457130Z",
     "shell.execute_reply.started": "2025-07-19T09:16:15.517560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 09:16:15 nemo_logging:393] Dataset loaded with 130 files totalling 0.10 hours\n",
      "[NeMo I 2025-07-19 09:16:15 nemo_logging:393] 0 files were filtered totalling 0.00 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 09:16:16 nemo_logging:405] Passing in decoder_lengths=None for CTC decoding is likely to be an error, since it is unlikely that each element of your batch has exactly the same length. decoder_lengths will default to decoder_output.shape[0].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER = 0.9547218628719275\n"
     ]
    }
   ],
   "source": [
    "# Bigger batch-size = bigger throughput\n",
    "params['model']['validation_ds']['batch_size'] = 16\n",
    "\n",
    "# Setup the test data loader and make sure the model is on GPU\n",
    "first_asr_model.setup_test_data(test_data_config=params['model']['validation_ds'])\n",
    "first_asr_model.cuda()\n",
    "first_asr_model.eval()\n",
    "\n",
    "# We remove some preprocessing artifacts which benefit training\n",
    "first_asr_model.preprocessor.featurizer.pad_to = 0\n",
    "first_asr_model.preprocessor.featurizer.dither = 0.0\n",
    "\n",
    "# We will be computing Word Error Rate (WER) metric between our hypothesis and predictions.\n",
    "# WER is computed as numerator/denominator.\n",
    "# We'll gather all the test batches' numerators and denominators.\n",
    "wer_nums = []\n",
    "wer_denoms = []\n",
    "\n",
    "# Loop over all test batches.\n",
    "# Iterating over the model's `test_dataloader` will give us:\n",
    "# (audio_signal, audio_signal_length, transcript_tokens, transcript_length)\n",
    "# See the AudioToCharDataset for more details.\n",
    "for test_batch in first_asr_model.test_dataloader():\n",
    "        test_batch = [x.cuda() for x in test_batch]\n",
    "        targets = test_batch[2]\n",
    "        targets_lengths = test_batch[3]        \n",
    "        log_probs, encoded_len, greedy_predictions = first_asr_model(\n",
    "            input_signal=test_batch[0], input_signal_length=test_batch[1]\n",
    "        )\n",
    "        # Notice the model has a helper object to compute WER\n",
    "        first_asr_model.wer.update(greedy_predictions, None, targets, targets_lengths)\n",
    "        _, wer_num, wer_denom = first_asr_model.wer.compute()\n",
    "        wer_nums.append(wer_num.detach().cpu().numpy())\n",
    "        wer_denoms.append(wer_denom.detach().cpu().numpy())\n",
    "\n",
    "# We need to sum all numerators and denominators first. Then divide.\n",
    "print(f\"WER = {sum(wer_nums)/sum(wer_denoms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140dae72-b036-4392-9b4c-11caef3611a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# model finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92958dc-58cf-460a-af4f-6c156850b9d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:29:10.826581Z",
     "iopub.status.busy": "2025-07-19T09:29:10.826145Z",
     "iopub.status.idle": "2025-07-19T09:29:10.832749Z",
     "shell.execute_reply": "2025-07-19T09:29:10.831531Z",
     "shell.execute_reply.started": "2025-07-19T09:29:10.826548Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/jovyan/.cache/nemo-simple-example/\"\n",
    "train_manifest = data_dir + '/an4/train_manifest.json'\n",
    "test_manifest = data_dir + '/an4/test_manifest.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92cd546-e02a-4a1d-8df7-b8138520929f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:29:53.286353Z",
     "iopub.status.busy": "2025-07-19T09:29:53.285982Z",
     "iopub.status.idle": "2025-07-19T09:29:53.316368Z",
     "shell.execute_reply": "2025-07-19T09:29:53.315607Z",
     "shell.execute_reply.started": "2025-07-19T09:29:53.286323Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "params = OmegaConf.load(\"./configs/config_bpe.yaml\")\n",
    "params.model.train_ds.manifest_filepath = train_manifest\n",
    "params.model.validation_ds.manifest_filepath = test_manifest\n",
    "params.model.spec_augment.rect_masks = 0\n",
    "\n",
    "new_opt = copy.deepcopy(params.model.optim)\n",
    "new_opt.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502dd133-2c60-45fe-a21f-dcd9154c45e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:29:54.470494Z",
     "iopub.status.busy": "2025-07-19T09:29:54.470095Z",
     "iopub.status.idle": "2025-07-19T09:30:00.987650Z",
     "shell.execute_reply": "2025-07-19T09:30:00.986630Z",
     "shell.execute_reply.started": "2025-07-19T09:29:54.470463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Corpus already exists at path : /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/text_corpus/document.txt\n",
      "\u001b[2K[00:00:00] Tokenize words                 ██████████████████ 99       /       99[00:00:00] Tokenize words                 ██████████████████ 0        /        0\n",
      "\u001b[2K[00:00:00] Count pairs                    ██████████████████ 99       /       99\n",
      "\u001b[2K[00:00:00] Compute merges                 ██████████████████ 11       /       11\n",
      "Serialized tokenizer at location : /home/jovyan/.cache/nemo-simple-example//tokenizers/an4/tokenizer_wpe_v64\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "!python ./scripts/tokenizers/process_asr_text_tokenizer.py \\\n",
    "  --manifest=\"{data_dir}/an4/train_manifest.json\" \\\n",
    "  --data_root=\"{data_dir}/tokenizers/an4/\" \\\n",
    "  --vocab_size=64 \\\n",
    "  --tokenizer=\"wpe\" \\\n",
    "  --no_lower_case \\\n",
    "  --log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c45a829a-698d-4eab-8d9e-bab083d8d6d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:31:28.642123Z",
     "iopub.status.busy": "2025-07-19T09:31:28.641807Z",
     "iopub.status.idle": "2025-07-19T09:31:28.893783Z",
     "shell.execute_reply": "2025-07-19T09:31:28.892935Z",
     "shell.execute_reply.started": "2025-07-19T09:31:28.642098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 09:31:28 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 32 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 09:31:28 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /home/jovyan/.cache/nemo-simple-example//an4/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shard_strategy: scatter\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-07-19 09:31:28 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /home/jovyan/.cache/nemo-simple-example//an4/test_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 09:31:28 nemo_logging:393] PADDING: 16\n",
      "[NeMo I 2025-07-19 09:31:28 nemo_logging:393] Model EncDecCTCModelBPE was successfully restored from /home/jovyan/.cache/nemo-simple-example/first_model.nemo.\n"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "restored_model = nemo_asr.models.EncDecCTCModelBPE.restore_from(f\"{data_dir}/first_model.nemo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e826bf-cb4b-436c-9dd8-aab7a7e54ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:31:31.138817Z",
     "iopub.status.busy": "2025-07-19T09:31:31.138357Z",
     "iopub.status.idle": "2025-07-19T09:31:31.381449Z",
     "shell.execute_reply": "2025-07-19T09:31:31.380504Z",
     "shell.execute_reply.started": "2025-07-19T09:31:31.138785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 09:31:31 nemo_logging:405] You tried to register an artifact under config key=tokenizer.vocab_path but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '▁', 'e', 't', 'r', 'o', 'a', 'h', '▁one', '▁two', 'u', 's', 'y', '▁six', '▁five', 'i', 'b', 'l', 'p', 'd', 'g', 'f', 'm', 'c', 'v', 'x', 'j', 'k', 'z', 'w', 'n', 'q']\n",
      "[NeMo I 2025-07-19 09:31:31 nemo_logging:393] Tokenizer AutoTokenizer initialized with 64 tokens\n",
      "[NeMo I 2025-07-19 09:31:31 nemo_logging:393] \n",
      "    Replacing old number of classes (32) with new number of classes - 64\n",
      "[NeMo I 2025-07-19 09:31:31 nemo_logging:393] Changed tokenizer to ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '##i', '##n', '##e', '##t', '##y', '##w', '##o', '##x', '##h', '##r', '##u', '##s', '##a', '##d', '##v', '##g', '##b', '##c', '##p', '##m', '##l', '##f', '##ne', '##ve', 'tw', 'one', 'two', '##ty', 'fi', '##ou', 'si', 'six', 'five'] vocabulary.\n"
     ]
    }
   ],
   "source": [
    "print(restored_model.decoder.vocabulary)\n",
    "\n",
    "restored_model.change_vocabulary(\n",
    "    new_tokenizer_dir=data_dir + \"/tokenizers/an4/tokenizer_wpe_v64/\",\n",
    "    new_tokenizer_type=\"wpe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "061d46c4-4199-4b3a-a8a0-17fb143bece7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:31:32.237258Z",
     "iopub.status.busy": "2025-07-19T09:31:32.236197Z",
     "iopub.status.idle": "2025-07-19T09:31:32.242135Z",
     "shell.execute_reply": "2025-07-19T09:31:32.241010Z",
     "shell.execute_reply.started": "2025-07-19T09:31:32.237224Z"
    }
   },
   "outputs": [],
   "source": [
    "params['model']['train_ds'][\"batch_size\"] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef2ff1b4-f9f1-4cc2-a17d-f6d19e38ee9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:31:33.047267Z",
     "iopub.status.busy": "2025-07-19T09:31:33.046855Z",
     "iopub.status.idle": "2025-07-19T09:31:33.181797Z",
     "shell.execute_reply": "2025-07-19T09:31:33.180994Z",
     "shell.execute_reply.started": "2025-07-19T09:31:33.047236Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 09:31:33 nemo_logging:405] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 09:31:33 nemo_logging:393] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.999]\n",
      "        capturable: False\n",
      "        decoupled_weight_decay: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.1\n",
      "        maximize: False\n",
      "        weight_decay: 0.0001\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-19 09:31:33 nemo_logging:405] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 09:31:33 nemo_logging:393] Dataset loaded with 948 files totalling 0.71 hours\n",
      "[NeMo I 2025-07-19 09:31:33 nemo_logging:393] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2025-07-19 09:31:33 nemo_logging:393] Dataset loaded with 130 files totalling 0.10 hours\n",
      "[NeMo I 2025-07-19 09:31:33 nemo_logging:393] 0 files were filtered totalling 0.00 hours\n"
     ]
    }
   ],
   "source": [
    "restored_model.setup_optimization(optim_config=new_opt)\n",
    "restored_model.setup_training_data(train_data_config=params['model']['train_ds'])\n",
    "restored_model.setup_validation_data(val_data_config=params['model']['validation_ds'])\n",
    "\n",
    "# # Freeze the encoder layers (should not be done for finetuning, only done for demo)\n",
    "restored_model.encoder.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb7a4d7f-0d9d-4466-9654-2ed2f3871447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T09:31:34.462025Z",
     "iopub.status.busy": "2025-07-19T09:31:34.461611Z",
     "iopub.status.idle": "2025-07-19T09:33:15.714482Z",
     "shell.execute_reply": "2025-07-19T09:33:15.713369Z",
     "shell.execute_reply.started": "2025-07-19T09:31:34.461994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-19 09:31:34 nemo_logging:393] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.999]\n",
      "        capturable: False\n",
      "        decoupled_weight_decay: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.1\n",
      "        maximize: False\n",
      "        weight_decay: 0.0001\n",
      "    )\n",
      "[NeMo I 2025-07-19 09:31:34 nemo_logging:393] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f84344c66c0>\" \n",
      "    will be used during training (effective maximum steps = 2380) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: 0.05\n",
      "    min_lr: 1.0e-06\n",
      "    last_epoch: -1\n",
      "    max_steps: 2380\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params | Mode \n",
      "--------------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0      | train\n",
      "1 | encoder           | ConvASREncoder                    | 1.2 M  | eval \n",
      "2 | spec_augmentation | SpectrogramAugmentation           | 0      | train\n",
      "3 | wer               | WER                               | 0      | train\n",
      "4 | decoder           | ConvASRDecoder                    | 66.6 K | train\n",
      "5 | loss              | CTCLoss                           | 0      | train\n",
      "--------------------------------------------------------------------------------\n",
      "66.6 K    Trainable params\n",
      "1.2 M     Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.983     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "126       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0886513f09448e2a027ab14156b28e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3278ee8edc42b5bbafddf2abed5ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412f7a934c4142d39c6a387b7a8e7afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bc6b19b14e4e43a339cbe4811cb1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9315092e37b84de0a3905cce5df5c007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72675b21265497fbe631d969ca56e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83f310c2cad421f9ca6ce5242966dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86373f02f004ca4adaea59981f17c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662a9625270b48f09907fb5393a9f809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28373a46e37b4e5e82f558c455e06f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9107d1a229184aca95d0ccd3938e2188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b067b4bd0ee649609c4247913299d4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486ab5842d9547e79eeeaf9f4e176cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b692ea6dbdeb4bbcac9bc21d3bf1c81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fd63d917c648ce9f218b18000586cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9419b7acd3646c9b6d8fccc6eb39f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f3ce32331c4294947151bf95e338bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a451195052c4b1ea0d047ed46f84fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c15c32f0204b4e9de0b01a68b6fb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a9376498a04fd19cfd42bd09edb059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a01d3aad4584d15a3eaec5d54261f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cc40ba57c748aebbe9f96b8d5b5a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(devices=1, accelerator='gpu', max_epochs=20)\n",
    "trainer.fit(restored_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0554cfe-f060-4ed0-b8e3-180e7defda51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
